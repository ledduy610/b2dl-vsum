{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VSUM.SurveyDeepLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ledduy610/b2dl-vsum/blob/main/VSUM_SurveyDeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF_YKd3e_x99"
      },
      "source": [
        "# Deep Learning VSUM\n",
        " \n",
        "Video Summarization Using Deep Neural Networks: A Survey\n",
        "\n",
        "[//]: # (Video summarization aims to generate a short synopsis that summarizes the video content by selecting its most informa- tive and important parts. The produced summary is usually composed of a set of representative video frames <a.k.a. video key-frames>, or video fragments <a.k.a. video key-fragments> that have been stitched in chronological order to form a shorter video. The former type of a video summary is known as video storyboard, and the latter type is known as video skim. One advantage of video skims over static sets of frames is the ability to include audio and motion elements that offer a more natural story narration and potentially enhance the expressiveness and the amount of information conveyed by the video summary. Furthermore, it is often more entertaining and interesting for the viewer to watch a skim rather than a slide show of frames [11]. On the other hand, storyboards are not restricted by timing or synchronization issues and, therefore, they offer more flexibility in terms of data or )\n",
        "\n",
        "Công việc chính trong giản lược video là tạo ra một bản tóm tắt ngắn có thể khái quát nội dung của video ban đầu bằng cách chọn lọc những phần quan trọng, có chứa nhiều thông tin trong video đó. Kết quả của quá trình giản lược video thông thường sẽ là một tập hợp các khung hình đại diện (gọi là key-frames) hoặc một tập hợp các trích đoạn (video key-segment) được nối lại theo trình tự thời gian để tạo thành một video ngắn hơn.\n",
        "Bản giản lược trong trường hợp đầu tiên được gọi là **video storyboard** và trường hợp thứ hai được gọi là **video skim**. \n",
        "\n",
        "Trong thực tiễn ứng dụng, video skim thường có nhiều ưu điểm hơn so với video storyboard - vốn chỉ là một tập hợp các bức ảnh tĩnh. Video skim có thể được đính kèm âm thanh và thể hiện được các cảnh chuyển động, cho phép diễn tả một cách tự nhiên, gần gũi và đầy đủ hơn nội dung của video ban đầu. Bên cạnh đó, xem một video ngắn thường sẽ mang lại giá trị giải trí cao hơn cho người dùng so với việc nhìn một loạt hình ảnh tĩnh rời rạc nhau. Video storyboard sẽ có lợi thế trong một số trường hợp đặc biệt do khung hình (video frame) có thể được trình bày một cách độc lập nhau, không bị ràng buộc bởi thứ tự thời gian, mang lại một sự uyển chuyển nhất định khi tổ chức thực hiện duyệt lướt video."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUGuXRbWEb1F"
      },
      "source": [
        "![Fig1.png](https://raw.githubusercontent.com/ledduy610/b2dl-vsum/main/figs/2021.VSUM.Survey.Fig1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_lY7gncPFtV"
      },
      "source": [
        "[//]: # (A high-level representation of the typical deep-learning- based video summarization pipeline is depicted in Fig. 1. The first step of the analysis involves the representation of the visual content of the video with the help of feature vectors. Most commonly, such vectors are extracted at the frame-level, for all frames or for a subset of them selected via a frame- sampling strategy, e.g., processing 2 frames per second. In this way, the extracted feature vectors store information at a very detailed level and capture the dynamics of the visual content that are of high significance when selecting the video parts that form the summary. Typically, in most deep-learning- based video summarization techniques the visual content of the video frames is represented by deep feature vectors extracted with the help of pre-trained neural networks. For this, a variety of Convolutional Neural Networks <CNNs> and Deep Convolutional Neural Networks <DCNNs> have been used in the bibliography, that include GoogleNet <Inception V1> [14], Inception V3 [15], AlexNet [16], variations of ResNet [17] and variations of VGGnet [18]. Nevertheless, the GoogleNet appears to be the most commonly used one thus far. The extracted features are then utilized by a deep summarizer network, which is trained by trying to minimize an objective function or a set of objective functions. )\n",
        "\n",
        "Hình 1 mô tả một cách chi tiết các bước thường gặp trong quy trình (pipeline) giản lược video sử dụng phương pháp học sâu (deep-learning). Bước đầu tiên thường sẽ là biểu diễn nội dung hình ảnh của video thông qua các vector đặc trưng (feature vectors). Các nội dung hình ảnh này thường sẽ được trích xuất ở cấp độ từng khung hình, có thể là thực hiện cho tất cả khung hình trong video hoặc cho một số lượng khung hình nào đó theo quy ước có trước (ví dụ như trích xuất đặc trưng cho 2 khung hình trong mỗi giây của video ban đầu). \n",
        "Những mạng neural đã được train sẵn trong lĩnh vực thị giác máy tính sẽ để trích xuất các vector đặc trưng học sâu (deep feature vector) cho việc biểu diễn nội dung hình ảnh của mỗi khung hình trong video. \n",
        "Đã có nhiều công trình khác nhau, sử dụng các kiến trúc mạng như GoogleNet, AlexNet, các biến thể của ResNet, VGGnet hay Inception cho bước này. \n",
        "Những vector đặc trưng học sâu được rút trích từ mỗi khung hình sẽ cho phép máy tính có thể nắm bắt và xử lý được các nội dung trực quan của video, một yếu tố rất quan trọng để có thể quyết định phần nào của video nên được giữ lại trong bản giản lược."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD5cyMvIwjIz"
      },
      "source": [
        "Ở bước tiếp theo trong quy trình giản lược video, một mạng học sâu sẽ được xây dựng để có thể dự đoán mức độ quan trọng (importance score) của mỗi khung hình từ vector đặc trưng được trích xuất cho khung hình đó trong bước đầu. Độ quan trọng của khung hình sẽ cố gắng phản ánh các tiêu chuẩn mà con người thường đặt ra để quyết định chọn lựa khung hình khi tiến hành giản lược video, ví dụ như khối lượng thông tin của khung hình, tính đại diện của khung hình đối với video gốc, chất lượng của hình ảnh, v.v... \n",
        "Việc tính toán importance score thường được thực hiện bởi một kiến trúc các **mạng neural học sâu cho giản lược video** - tạm gọi là **deep summarizer network (DSN)**.\n",
        "\n",
        "\n",
        "Kết quả từ Deep summarizer network sẽ được sử dụng để xây dựng nên bản giản lược cuối cùng cho video. Để tạo ra video storyboard, người ta có thể dùng một phương pháp đơn giản là chọn ra các khung hình có importance score cao nhất sao cho đảm bảo hạn chế tối đa sự trùng lắp về mặt trực quan hình ảnh. \n",
        "Tạo ra video skim sẽ tương đối khó khăn hơn và đây là mục tiêu nghiên cứu của đa số các công trình liên quan đến giản lược video. \n",
        "\n",
        "Để có một bản video skim, người ta sẽ cần thêm một bước phân đoạn video (video segmentation) thành từng trích đoạn liên tiếp và không chồng lên nhau. Việc phân đoạn video phải đảm bảo tính **liền mạch về mặt trực quan (visual coherence)** và **liền mạch về mặt tiết tấu (temporal coherence)** trong mỗi đoạn. Điều này nhằm đảm bảo khi ghép các đoạn video nhỏ này vào trong bản video skim chúng ta sẽ được một video giản lược liền mạch và hấp dẫn đối với người xem. Sau khi phân đoạn video, người ta sẽ tổng hợp importance score cho từng đoạn video dựa trên importance score đã được Deep summarizer network xác định cho các khung hình có trong đoạn đó. \n",
        "Việc tổng hợp importance score của các segment có thể sử dụng cách  tính tổng hoặc tính trung bình cộng score của từng khung hình, tùy ngữ cảnh ứng dụng. \n",
        "Cuối cùng, để xác định xem các đoạn video nào được đưa vào bản giản lược thì thông thường ngữ cảnh ứng dụng sẽ quy định độ dài tối đa của video skim (ví dụ như 10% - 15% độ dài  của video ban đầu). Như vậy, ta cần chọn ra các đoạn video sao cho tổng độ dài của chúng không vượt quá độ dài quy định và tổng importance score của chúng là lớn nhất. Đây chính là **bài toán cái ba lô (knapsack problem)**, có thể được giải bằng kỹ thuật **quy hoạch động (dynamic programming)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BzwnCE6ZbeU"
      },
      "source": [
        "[//]: # (With regards to the utilized type of data, the current bibli- ography on deep-learning-based video summarization can be divided between: • Unimodal approaches that utilize only the visual modality of the videos for feature extraction, and learn summariza- tion in a <weakly->supervised or unsupervised manner. • Multimodal methods that exploit the available textual metadata and learn semantic/category-driven summariza- tion in a supervised way by increasing the relevance between the semantics of the summary and the semantics of the associated metadata or video category. Concerning the adopted training strategy, the existing deep-learning-based video summarization algorithms can be coarsely categorized in the following categories: • Supervised approaches that rely on datasets with human- labeled ground-truth annotations <either in the form of video summaries, as in the case of the SumMe dataset [19], or in the form of frame-level importance scores, as in the case of the TVSum dataset [20]>, based on which they try to discover the underlying criterion for video frame/fragment selection and video summarization. • Unsupervised approaches that overcome the need for ground-truth data <whose production requires time- demanding and laborious manual annotation procedures>, based on learning mechanisms that require only an adequately large collection of original videos for their training. • Weakly-supervised approaches that, similarly to unsu- pervised approaches, aim to alleviate the need for large sets of hand-labeled data. Less-expensive weak labels are utilized with the understanding that they are imperfect compared to a full set of human annotations, but can nonetheless be used to create strong predictive models. Building on the above described categorizations, a more detailed taxonomy of the relevant bibliography is depicted in Fig. 2. The penultimate layer of this arboreal illustration shows the different learning approaches that have been adopted. The leafs of each node of this layer show the utilized techniques for implementing each learning approach, and contain references to the most relevant works in the bibliography. This taxonomy will be the basis for presenting the relevant bibliography in the following section. )\n",
        "\n",
        "Để phân loại các hướng tiếp cận hiện có đối với bài toán giản lược video, nếu xét theo mức độ tận dụng dữ liệu có thể chia các hướng tiếp cận thành hai nhánh chính. \n",
        "* Nhánh tiếp cận umiodal cố gắng tạo ra bản giản lược chỉ từ các thông tin hình ảnh trực quan có sẵn trong video. Đây là hướng tiếp cận có nhiều nghiên cứu theo đuổi nhất, một phần do tiềm năng ứng dụng rộng rãi và tổng quát trên tất cả các thể loại video.\n",
        "* Nhánh tiếp cận multimodal sử dụng tất cả các thông tin có liên quan đến video để xây dựng bản giản lược, bao gồm cả thông tin âm thanh và các siêu dữ liệu ở dạng văn bản đi kèm với video. Hướng tiếp cận này tuy tận dụng được nhiều thông tin liên quan đến ngữ nghĩa của video nhưng lại thiếu tính tổng quát vì các dạng siêu dữ liệu đi kèm của video thường không đầy đủ hoặc được trình bày rất khác nhau tùy theo từng thể loại video. \n",
        "\n",
        "Nếu phân loại theo các mô hình học máy được sử dụng khi xây dựng Deep summarizer network, chúng ta có thể chia các hướng tiếp cận cho bài toán giản lược video thành 03 nhánh chính\n",
        "* Các hướng tiếp cận học có giám sát sử dụng các bộ dữ liệu huấn luyện đã được con người gán nhãn từ trước. Nhãn gán ở đây có thể ở dạng các bản video giản lược mẫu (như trong bộ dữ liệu SumMe) hay ở dạng các giá trị importance score mẫu cho từng khung hình trong video (như trong bộ dữ liệu TVSum)\n",
        "* Các hướng tiếp cận học không giám sát sử dụng nhiều kỹ thuật học tăng cường, các môn hình GAN và nhiều phương pháp khác để hướng đến việc giảm sự lệ thuộc vào các bộ dữ liệu có gán nhãn sẵn (những bộ dữ liệu này đòi hỏi rất nhiều công sức để xây dựng thủ công và hiện vẫn chưa có nhiều bộ dữ liệu đủ lớn để phủ nhiều thể loại video khác nhau). \n",
        "* Các hướng tiếp cận weakly-supervised có cùng mục tiêu với hướng tiếp cận học không giám sát. Đó là giảm sự lệ thuộc vào dữ liệu gán nhãn sẵn bằng cách tận dụng những bộ dữ liệu khác không đầy đủ như TVSum hay SumMe nhưng có phương án gán nhãn đòi hỏi ít sức lao động của con người hơn.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elOKuM1rrxTu"
      },
      "source": [
        "![Fig2.png] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RA8hDM3IBMqR"
      },
      "source": [
        "## PROBLEM STATEMENT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_KUAtYTBQv9"
      },
      "source": [
        ""
      ]
    }
  ]
}