{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VSUM.SUM-GAN.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ledduy610/uit-vsum/blob/main/VSUM_SUM_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIUPxVj7ru-0"
      },
      "source": [
        "# Unsupervised Video Summarization\n",
        "\n",
        "Paper: \n",
        "* AC-SUM-GAN: Connecting Actor-Critic and Generative Adversarial Networks for Unsupervised Video Summarization (IEEE TCSVT 2020) https://www.iti.gr/~bmezaris/publications/csvt20_preprint.pdf\n",
        "* A Stepwise, Label-based Approach for Improving the Adversarial Training in Unsupervised Video Summarization (2019) https://www.iti.gr/~bmezaris/publications/acmmm2019_preprint.pdf\n",
        "* Unsupervised Video Summarization via Attention-Driven Adversarial Learning (2020) https://www.iti.gr/~bmezaris/publications/mmm2020_lncs11961_1_preprint.pdf\n",
        "* Unsupervised Video Summarization with Adversarial LSTM Networks (CVPR 2017) http://web.engr.oregonstate.edu/~sinisa/research/publications/cvpr17_summarization.pdf\n",
        "\n",
        "\n",
        "Repos\n",
        "* https://github.com/e-apostolidis\n",
        "* https://github.com/e-apostolidis/AC-SUM-GAN\n",
        "* https://github.com/e-apostolidis/SUM-GAN-sl\n",
        "* https://github.com/e-apostolidis/SUM-GAN-AAE\n",
        "* https://github.com/e-apostolidis/PoR-Summarization-Measure\n",
        "* https://github.com/j-min/Adversarial_Video_Summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7lhkaOwBRmp"
      },
      "source": [
        "# Mục mới"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pGJDaVHVndG"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HOLLdccJCDu"
      },
      "source": [
        "## Link to GDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1dovhXMrn0u"
      },
      "source": [
        "\n",
        "szRootDir = '/content/drive/MyDrive/0.Desktop/VSUM-Colab/' #Duy\n",
        "szRootDir = '/content/drive/MyDrive/temp/' #An\n",
        "\n",
        "%cd $szRootDir \n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0ZHUqvLKr05"
      },
      "source": [
        "## Clone repos\n",
        "* https://github.com/e-apostolidis/SUM-GAN-sl.git\n",
        "* https://github.com/e-apostolidis/SUM-GAN-AAE.git\n",
        "* https://github.com/e-apostolidis/AC-SUM-GAN.git\n",
        "* https://github.com/e-apostolidis/PoR-Summarization-Measure.git\n",
        "* https://github.com/j-min/Adversarial_Video_Summary.git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6EDczScKSiM"
      },
      "source": [
        "!git clone https://github.com/e-apostolidis/SUM-GAN-sl.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sroGlICQKqax"
      },
      "source": [
        "!git clone https://github.com/e-apostolidis/SUM-GAN-AAE.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6vE3DrBK8tV"
      },
      "source": [
        "!git clone https://github.com/e-apostolidis/AC-SUM-GAN.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O82o1HviLISz"
      },
      "source": [
        "!git clone https://github.com/e-apostolidis/PoR-Summarization-Measure.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9Uwj6arPWog"
      },
      "source": [
        "!git clone https://github.com/j-min/Adversarial_Video_Summary.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKIvy8dlb4xw"
      },
      "source": [
        "## Data\n",
        "Structured h5 files with the video features and annotations of the SumMe and TVSum datasets are available within the \"data\" folder. The GoogleNet features of the video frames were extracted by [Ke Zhang](https://github.com/kezhang-cs) and [Wei-Lun Chao](https://github.com/pujols) and the h5 files were obtained from [Kaiyang Zhou](https://github.com/KaiyangZhou/pytorch-vsumm-reinforce). These files have the following structure:\n",
        "<pre>\n",
        "/key\n",
        "    /features                 2D-array with shape (n_steps, feature-dimension)\n",
        "    /gtscore                  1D-array with shape (n_steps), stores ground truth improtance score (used for training, e.g. regression loss)\n",
        "    /user_summary             2D-array with shape (num_users, n_frames), each row is a binary vector (used for test)\n",
        "    /change_points            2D-array with shape (num_segments, 2), each row stores indices of a segment\n",
        "    /n_frame_per_seg          1D-array with shape (num_segments), indicates number of frames in each segment\n",
        "    /n_frames                 number of frames in original video\n",
        "    /picks                    positions of subsampled frames in original video\n",
        "    /n_steps                  number of subsampled frames\n",
        "    /gtsummary                1D-array with shape (n_steps), ground truth summary provided by user (used for training, e.g. maximum likelihood)\n",
        "    /video_name (optional)    original video name, only available for SumMe dataset\n",
        "</pre>\n",
        "Original videos and annotations for each dataset are also available in the authors' project webpages:\n",
        "- TVSum dataset: https://github.com/yalesong/tvsum\n",
        "- SumMe dataset: https://gyglim.github.io/me/vsum/index.html#benchmark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QRiHHb0O8yd"
      },
      "source": [
        "### SUM-GAN-sl\n",
        "\n",
        "* https://github.com/e-apostolidis/SUM-GAN-sl"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtdzJ2yqPGAi"
      },
      "source": [
        "szRootDir = szRootDir + '/SUM-GAN-sl' #Duy\n",
        "%cd $szRootDir \n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77_yarO7PZKS"
      },
      "source": [
        "### Training\n",
        "To train the model using one of the aforementioned datasets and for a number of randomly created splits of the dataset (where in each split 80% of the data is used for training and 20% for testing) use the corresponding JSON file that is included in the \"data/splits\" directory. This file contains the 5 randomly generated splits that were utilized in our experiments.\n",
        "\n",
        "For training the model using a single split, run:\n",
        "<pre>\n",
        "python main.py --split_index N (with N being the index of the split)\n",
        "</pre>\n",
        "Alternatively, to train the model for all 5 splits, use the 'run_splits.sh' script according to the following:\n",
        "<pre>\n",
        "chmod +x run_splits.sh    # Makes the script executable.\n",
        "./run_splits              # Runs the script.  \n",
        "</pre>\n",
        "Please note that after each training epoch the algorithm performs an evaluation step, and uses the trained model to compute the importance scores for the frames of each test video. These scores are then used by the provided evaluation scripts to assess the overal performance of the model (in F-Score).\n",
        "\n",
        "The progress of the training can be monitored via the TensorBoard platform and by:\n",
        "- opening a command line (cmd) and running: tensorboard --logdir=/path/to/log-directory --host=localhost\n",
        "- opening a browser and pasting the returned URL from cmd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lHKDw1MSny4"
      },
      "source": [
        "!pip install TensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGd60Y8wBP0n"
      },
      "source": [
        "%cd \"$szRootDir/data/SumMe\"\n",
        "!unrar x eccv16_dataset_summe_google_pool5.rar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fou4r8dvBnxK"
      },
      "source": [
        "%cd \"$szRootDir/data/TVSum\"\n",
        "!unrar x eccv16_dataset_tvsum_google_pool5.rar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCS8gWbeP5mp"
      },
      "source": [
        "import os\n",
        " \n",
        "print(\"pwd=%s\" % os.getcwd()) # old style formating\n",
        "\n",
        "# In courtersy of : https://stackoverflow.com/questions/49264194/import-py-file-in-another-directory-in-jupyter-notebook\n",
        "import sys  \n",
        "sys.path.insert(0, szRootDir + \"/model/\")\n",
        "print(sys.path)\n",
        "\n",
        "%cd $szRootDir/model\n",
        "!pwd "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL0goIdmPNTP"
      },
      "source": [
        "%cd $szRootDir/model\n",
        "!pwd \n",
        "!python main.py --split_index 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NItKCf4W3Vxz"
      },
      "source": [
        "!pwd\n",
        "!ls\n",
        "\n",
        "#Solver.evaluate didn't have the code to create subdirectory in exp folder, we have to create it ourself\n",
        "\n",
        "!mkdir -p ../exp1/SumMe/models/split1\n",
        "!mkdir -p ../exp1/SumMe/results/split1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSxIntl88spM"
      },
      "source": [
        "sys.argv = 'main.py --split_index 1'.split()\n",
        "config = get_config(mode='train')\n",
        "test_config = get_config(mode='test')\n",
        "\n",
        "print(config)\n",
        "print(test_config)\n",
        "print('split_index:', config.split_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG4D_a3o6eRe"
      },
      "source": [
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import json\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from layers import Summarizer, Discriminator\n",
        "from utils import TensorboardWriter\n",
        "\n",
        "# labels for training the GAN part of the model\n",
        "original_label = torch.tensor(1.0).cuda()\n",
        "summary_label = torch.tensor(0.0).cuda()\n",
        "\n",
        "class Solver(object):\n",
        "    def __init__(self, config=None, train_loader=None, test_loader=None):\n",
        "        \"\"\"Class that Builds, Trains and Evaluates SUM-GAN-sl model\"\"\"\n",
        "        self.config = config\n",
        "        self.train_loader = train_loader\n",
        "        self.test_loader = test_loader\n",
        "\n",
        "    def build(self):\n",
        "\n",
        "        # Build Modules\n",
        "        self.linear_compress = nn.Linear(\n",
        "            self.config.input_size,\n",
        "            self.config.hidden_size).cuda()\n",
        "        self.summarizer = Summarizer(\n",
        "            input_size=self.config.hidden_size,\n",
        "            hidden_size=self.config.hidden_size,\n",
        "            num_layers=self.config.num_layers).cuda()\n",
        "        self.discriminator = Discriminator(\n",
        "            input_size=self.config.hidden_size,\n",
        "            hidden_size=self.config.hidden_size,\n",
        "            num_layers=self.config.num_layers).cuda()\n",
        "        self.model = nn.ModuleList([\n",
        "            self.linear_compress, self.summarizer, self.discriminator])\n",
        "\n",
        "        if self.config.mode == 'train':\n",
        "            # Build Optimizers\n",
        "            self.s_e_optimizer = optim.Adam(\n",
        "                list(self.summarizer.s_lstm.parameters())\n",
        "                + list(self.summarizer.vae.e_lstm.parameters())\n",
        "                + list(self.linear_compress.parameters()),\n",
        "                lr=self.config.lr)\n",
        "            self.d_optimizer = optim.Adam(\n",
        "                list(self.summarizer.vae.d_lstm.parameters())\n",
        "                + list(self.linear_compress.parameters()),\n",
        "                lr=self.config.lr)\n",
        "            self.c_optimizer = optim.Adam(\n",
        "                list(self.discriminator.parameters())\n",
        "                + list(self.linear_compress.parameters()),\n",
        "                lr=self.config.discriminator_lr)\n",
        "\n",
        "            self.writer = TensorboardWriter(str(self.config.log_dir))\n",
        "\n",
        "    def reconstruction_loss(self, h_origin, h_sum):\n",
        "        \"\"\"L2 loss between original-regenerated features at cLSTM's last hidden layer\"\"\"\n",
        "\n",
        "        return torch.norm(h_origin - h_sum, p=2)\n",
        "\n",
        "    def prior_loss(self, mu, log_variance):\n",
        "        \"\"\"KL( q(e|x) || N(0,1) )\"\"\"\n",
        "        return 0.5 * torch.sum(-1 + log_variance.exp() + mu.pow(2) - log_variance)\n",
        "\n",
        "    def sparsity_loss(self, scores):\n",
        "        \"\"\"Summary-Length Regularization\"\"\"\n",
        "\n",
        "        return torch.abs(torch.mean(scores) - self.config.regularization_factor)\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    def train(self):\n",
        "        step = 0\n",
        "        for epoch_i in trange(self.config.n_epochs, desc='Epoch', ncols=80):\n",
        "            s_e_loss_history = []\n",
        "            d_loss_history = []\n",
        "            c_original_loss_history = []\n",
        "            c_summary_loss_history = []\n",
        "            for batch_i, image_features in enumerate(tqdm(\n",
        "                    self.train_loader, desc='Batch', ncols=80, leave=False)):\n",
        "\n",
        "                self.model.train()\n",
        "\n",
        "                # [batch_size=1, seq_len, 1024]\n",
        "                # [seq_len, 1024]\n",
        "                image_features = image_features.view(-1, self.config.input_size)\n",
        "\n",
        "                # [seq_len, 1024]\n",
        "                image_features_ = Variable(image_features).cuda()\n",
        "\n",
        "                #---- Train sLSTM, eLSTM ----#\n",
        "                if self.config.verbose:\n",
        "                    tqdm.write('\\nTraining sLSTM and eLSTM...')\n",
        "\n",
        "                # [seq_len, 1, hidden_size]\n",
        "                original_features = self.linear_compress(image_features_.detach()).unsqueeze(1)\n",
        "\n",
        "                scores, h_mu, h_log_variance, generated_features = self.summarizer(original_features)\n",
        "\n",
        "                h_origin, original_prob = self.discriminator(original_features)\n",
        "                h_sum, sum_prob = self.discriminator(generated_features)\n",
        "\n",
        "                tqdm.write(f'original_p: {original_prob.item():.3f}, summary_p: {sum_prob.item():.3f}')\n",
        "\n",
        "                reconstruction_loss = self.reconstruction_loss(h_origin, h_sum)\n",
        "                prior_loss = self.prior_loss(h_mu, h_log_variance)\n",
        "                sparsity_loss = self.sparsity_loss(scores)\n",
        "\n",
        "                tqdm.write(f'recon loss {reconstruction_loss.item():.3f}, prior loss: {prior_loss.item():.3f}, sparsity loss: {sparsity_loss.item():.3f}')\n",
        "\n",
        "                s_e_loss = reconstruction_loss + prior_loss + sparsity_loss\n",
        "\n",
        "                self.s_e_optimizer.zero_grad()\n",
        "                s_e_loss.backward()\n",
        "                # Gradient cliping\n",
        "                torch.nn.utils.clip_grad_norm(self.model.parameters(), self.config.clip)\n",
        "                self.s_e_optimizer.step()\n",
        "\n",
        "                s_e_loss_history.append(s_e_loss.data)\n",
        "\n",
        "                #---- Train dLSTM (generator) ----#\n",
        "                if self.config.verbose:\n",
        "                    tqdm.write('Training dLSTM...')\n",
        "\n",
        "                # [seq_len, 1, hidden_size]\n",
        "                original_features = self.linear_compress(image_features_.detach()).unsqueeze(1)\n",
        "\n",
        "                scores, h_mu, h_log_variance, generated_features = self.summarizer(original_features)\n",
        "\n",
        "                h_origin, original_prob = self.discriminator(original_features)\n",
        "                h_sum, sum_prob = self.discriminator(generated_features)\n",
        "\n",
        "                tqdm.write(f'original_p: {original_prob.item():.3f}, summary_p: {sum_prob.item():.3f}')\n",
        "\n",
        "                reconstruction_loss = self.reconstruction_loss(h_origin, h_sum)\n",
        "                g_loss = self.criterion(sum_prob, original_label)\n",
        "\n",
        "                tqdm.write(f'recon loss {reconstruction_loss.item():.3f}, g loss: {g_loss.item():.3f}')\n",
        "\n",
        "                d_loss = reconstruction_loss + g_loss\n",
        "\n",
        "                self.d_optimizer.zero_grad()\n",
        "                d_loss.backward()\n",
        "                # Gradient cliping\n",
        "                torch.nn.utils.clip_grad_norm(self.model.parameters(), self.config.clip)\n",
        "                self.d_optimizer.step()\n",
        "\n",
        "                d_loss_history.append(d_loss.data)\n",
        "\n",
        "                #---- Train cLSTM ----#\n",
        "                if self.config.verbose:\n",
        "                    tqdm.write('Training cLSTM...')\n",
        "\n",
        "                self.c_optimizer.zero_grad()\n",
        "\n",
        "                # Train with original loss\n",
        "                # [seq_len, 1, hidden_size]\n",
        "                original_features = self.linear_compress(image_features_.detach()).unsqueeze(1)\n",
        "                h_origin, original_prob = self.discriminator(original_features)\n",
        "                c_original_loss = self.criterion(original_prob, original_label)\n",
        "                c_original_loss.backward()\n",
        "\n",
        "                # Train with summary loss\n",
        "                scores, h_mu, h_log_variance, generated_features = self.summarizer(original_features)\n",
        "                h_sum, sum_prob = self.discriminator(generated_features.detach())\n",
        "                c_summary_loss = self.criterion(sum_prob, summary_label)\n",
        "                c_summary_loss.backward()\n",
        "                \n",
        "                tqdm.write(f'original_p: {original_prob.item():.3f}, summary_p: {sum_prob.item():.3f}')\n",
        "                tqdm.write(f'gen loss: {g_loss.item():.3f}')\n",
        "                \n",
        "                # Gradient cliping\n",
        "                torch.nn.utils.clip_grad_norm(self.model.parameters(), self.config.clip)\n",
        "                self.c_optimizer.step()\n",
        "\n",
        "                c_original_loss_history.append(c_original_loss.data)\n",
        "                c_summary_loss_history.append(c_summary_loss.data)\n",
        "                \n",
        "\n",
        "                if self.config.verbose:\n",
        "                    tqdm.write('Plotting...')\n",
        "\n",
        "                self.writer.update_loss(reconstruction_loss.data, step, 'recon_loss')\n",
        "                self.writer.update_loss(prior_loss.data, step, 'prior_loss')\n",
        "                self.writer.update_loss(sparsity_loss.data, step, 'sparsity_loss')\n",
        "                self.writer.update_loss(g_loss.data, step, 'gen_loss')\n",
        "\n",
        "                self.writer.update_loss(original_prob.data, step, 'original_prob')\n",
        "                self.writer.update_loss(sum_prob.data, step, 'sum_prob')\n",
        "\n",
        "                step += 1\n",
        "\n",
        "            s_e_loss = torch.stack(s_e_loss_history).mean()\n",
        "            d_loss = torch.stack(d_loss_history).mean()\n",
        "            c_original_loss = torch.stack(c_original_loss_history).mean()\n",
        "            c_summary_loss = torch.stack(c_summary_loss_history).mean()\n",
        "\n",
        "            # Plot\n",
        "            if self.config.verbose:\n",
        "                tqdm.write('Plotting...')\n",
        "            self.writer.update_loss(s_e_loss, epoch_i, 's_e_loss_epoch')\n",
        "            self.writer.update_loss(d_loss, epoch_i, 'd_loss_epoch')\n",
        "            self.writer.update_loss(c_original_loss, step, 'c_original_loss')\n",
        "            self.writer.update_loss(c_summary_loss, step, 'c_summary_loss')\n",
        "\n",
        "            # Save parameters at checkpoint\n",
        "            ckpt_path = str(self.config.save_dir) + f'/epoch-{epoch_i}.pkl'\n",
        "            tqdm.write(f'Save parameters at {ckpt_path}')\n",
        "            torch.save(self.model.state_dict(), ckpt_path)\n",
        "\n",
        "            self.evaluate(epoch_i)\n",
        "\n",
        "\n",
        "    def evaluate(self, epoch_i):\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        out_dict = {}\n",
        "\n",
        "        for video_tensor, video_name in tqdm(\n",
        "                self.test_loader, desc='Evaluate', ncols=80, leave=False):\n",
        "\n",
        "            # [seq_len, batch=1, 1024]\n",
        "            video_tensor = video_tensor.view(-1, self.config.input_size)\n",
        "            video_feature = Variable(video_tensor).cuda()\n",
        "\n",
        "            # [seq_len, 1, hidden_size]\n",
        "            video_feature = self.linear_compress(video_feature.detach()).unsqueeze(1)\n",
        "\n",
        "            # [seq_len]\n",
        "            with torch.no_grad():\n",
        "                scores = self.summarizer.s_lstm(video_feature).squeeze(1)\n",
        "                scores = scores.cpu().numpy().tolist()\n",
        "\n",
        "                out_dict[video_name] = scores\n",
        "\n",
        "            score_save_path = self.config.score_dir.joinpath(\n",
        "                f'{self.config.video_type}_{epoch_i}.json')\n",
        "            with open(score_save_path, 'w') as f:\n",
        "                tqdm.write(f'Saving score at {str(score_save_path)}.')\n",
        "                json.dump(out_dict, f)\n",
        "            score_save_path.chmod(0o777)\n",
        "\n",
        "    def pretrain(self):\n",
        "        pass\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J464UqDBWQ0"
      },
      "source": [
        "from configs import get_config\n",
        "#from solver import Solver\n",
        "from data_loader import get_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXAlfSoWzoSO"
      },
      "source": [
        "sys.argv = 'main.py --split_index 1'.split()\n",
        "config = get_config(mode='train')\n",
        "test_config = get_config(mode='test')\n",
        "\n",
        "print(config)\n",
        "print(test_config)\n",
        "print('split_index:', config.split_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSxfW2_N2Q6A"
      },
      "source": [
        "train_loader = get_loader(config.mode, config.split_index)\n",
        "test_loader = get_loader(test_config.mode, test_config.split_index)\n",
        "solver = Solver(config, train_loader, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5woa3M9Q2WDp"
      },
      "source": [
        "solver.build()\n",
        "solver.evaluate(-1)\t# evaluates the summaries generated using the initial random weights of the network \n",
        "solver.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRy1WV3OJRVl"
      },
      "source": [
        "## Adversarial_Video_Summary\n",
        "\n",
        "* https://github.com/j-min/Adversarial_Video_Summary\n",
        "\n",
        "Không chạy được"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2W55ZK4J14l"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqS49PcmJ2yZ"
      },
      "source": [
        "szRootDir = '/content/drive/MyDrive/0.Desktop/VSUM-Colab/Adversarial_Video_Summary' #Duy\n",
        "%cd $szRootDir \n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1DV4C2DKWMW"
      },
      "source": [
        "import os\n",
        " \n",
        "print(\"pwd=%s\" % os.getcwd()) # old style formating\n",
        "\n",
        "# In courtersy of : https://stackoverflow.com/questions/49264194/import-py-file-in-another-directory-in-jupyter-notebook\n",
        "import sys  \n",
        "sys.path.insert(0, szRootDir + \"/layers/\")\n",
        "print(sys.path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMoZ4REnK1jk"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bej5eNsrLNz6"
      },
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpmYMdwWK28r"
      },
      "source": [
        "#https://github.com/j-min/Adversarial_Video_Summary/blob/master/train.py\n",
        "\n",
        "from configs import get_config\n",
        "from solver import Solver\n",
        "from data_loader import get_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsBcyvpdOrbb"
      },
      "source": [
        "import sys\n",
        "sys.argv=['--mode train']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVmhok7kLSMP"
      },
      "source": [
        "config = get_config(mode='train')\n",
        "test_config = get_config(mode='test')\n",
        "print(config)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orznSOPdLZok"
      },
      "source": [
        "train_loader = get_loader(config.video_root_dir, config.mode)\n",
        "test_loader = get_loader(test_config.video_root_dir, test_config.mode)\n",
        "solver = Solver(config, train_loader, test_loader)\n",
        "\n",
        "solver.build()\n",
        "solver.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOIxHNl-f3gq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwPpfXrIgOvo"
      },
      "source": [
        "szDataFile = \"/content/drive/MyDrive/0.Desktop/VSUM-Colab/SUM-GAN-sl/data/TVSum/eccv16_dataset_tvsum_google_pool5.h5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHl3eRfPhDcT"
      },
      "source": [
        "import h5py\n",
        "\n",
        "print (h5py.__version__)\n",
        "\n",
        "fFile = h5py.File(szDataFile, \"r\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-26JGrlhZ6o"
      },
      "source": [
        "print(fFile.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaHr973mheeu"
      },
      "source": [
        "i = 0\n",
        "videoList = (list) (fFile.keys())\n",
        "videoData = fFile[videoList[i]]\n",
        "print(videoData)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsAXf0K9iJ00"
      },
      "source": [
        "#pick n_frames\n",
        "videoData['n_frames'][()]\n",
        "#videoData['gtsummary'].shape"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}