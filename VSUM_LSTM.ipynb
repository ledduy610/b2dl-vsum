{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VSUM.LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "uFRAAWRRRjoj",
        "sLo8FKSHhbJ8",
        "RNUiIkKmhLZT",
        "KvHlce3WjgcV",
        "SuOelH0uj9aI"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ledduy610/b2dl-vsum/blob/main/VSUM_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIUPxVj7ru-0"
      },
      "source": [
        "#Video Summarization with LSTM\n",
        "\n",
        "* Paper: http://www-scf.usc.edu/~zhan355/ke_eccv2016.pdf\n",
        "* Dataset: https://gitmemory.com/issue/KaiyangZhou/vsumm-reinforce/20/514498427\n",
        "* Dataset - same: https://github.com/ok1zjf/VASNet/blob/master/datasets_models_urls.txt - Đây là dataset được dùng chung cho các bài\n",
        "* ACCV2018: https://arxiv.org/pdf/1812.01969.pdf\n",
        "* AAAI2018: https://arxiv.org/pdf/1801.00054.pdf \n",
        "\n",
        "Repos\n",
        "* https://github.com/li-plus/DSNet\n",
        "* https://github.com/kezhang-cs/Video-Summarization-with-LSTM\n",
        "* https://github.com/KaiyangZhou/pytorch-vsumm-reinforce\n",
        "* https://github.com/ok1zjf/VASNet\n",
        "\n",
        "Tổ chức dữ liệu trong file .h5\n",
        "*https://github.com/KaiyangZhou/vsumm-reinforce/issues/1#issuecomment-363492711"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlTwIWQIgMjM"
      },
      "source": [
        "## Notes\n",
        "* Dữ liệu của VASNet sẽ được dùng chung cho các repos khác. Do đó chỉ download một lần, sau đó tạo các softlink thư mục datasets cho các repos khác (DSNet, pytorch-vsumm-reinforce)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kr8i_v8MbMjO"
      },
      "source": [
        "## Data\n",
        "Structured h5 files with the video features and annotations of the SumMe and TVSum datasets are available within the \"data\" folder. The GoogleNet features of the video frames were extracted by [Ke Zhang](https://github.com/kezhang-cs) and [Wei-Lun Chao](https://github.com/pujols) and the h5 files were obtained from [Kaiyang Zhou](https://github.com/KaiyangZhou/pytorch-vsumm-reinforce). These files have the following structure:\n",
        "<pre>\n",
        "/key\n",
        "    /features                 2D-array with shape (n_steps, feature-dimension)\n",
        "    /gtscore                  1D-array with shape (n_steps), stores ground truth improtance score (used for training, e.g. regression loss)\n",
        "    /user_summary             2D-array with shape (num_users, n_frames), each row is a binary vector (used for test)\n",
        "    /change_points            2D-array with shape (num_segments, 2), each row stores indices of a segment\n",
        "    /n_frame_per_seg          1D-array with shape (num_segments), indicates number of frames in each segment\n",
        "    /n_frames                 number of frames in original video\n",
        "    /picks                    positions of subsampled frames in original video\n",
        "    /n_steps                  number of subsampled frames\n",
        "    /gtsummary                1D-array with shape (n_steps), ground truth summary provided by user (used for training, e.g. maximum likelihood)\n",
        "    /video_name (optional)    original video name, only available for SumMe dataset\n",
        "</pre>\n",
        "Original videos and annotations for each dataset are also available in the authors' project webpages:\n",
        "- TVSum dataset: https://github.com/yalesong/tvsum\n",
        "- SumMe dataset: https://gyglim.github.io/me/vsum/index.html#benchmark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HOLLdccJCDu"
      },
      "source": [
        "## Link to GDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1dovhXMrn0u"
      },
      "source": [
        "szRootDir = '/content/drive/MyDrive/0.Desktop/VSUM-Colab/' #Duy\n",
        "%cd $szRootDir \n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0ZHUqvLKr05"
      },
      "source": [
        "## Clone repos\n",
        "* https://github.com/kezhang-cs/Video-Summarization-with-LSTM.git\n",
        "* https://github.com/ok1zjf/VASNet.git\n",
        "* https://github.com/KaiyangZhou/pytorch-vsumm-reinforce.git\n",
        "* https://github.com/li-plus/DSNet.git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6EDczScKSiM"
      },
      "source": [
        "!git clone https://github.com/kezhang-cs/Video-Summarization-with-LSTM.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sroGlICQKqax"
      },
      "source": [
        "!git clone https://github.com/ok1zjf/VASNet.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6vE3DrBK8tV"
      },
      "source": [
        "!git clone https://github.com/KaiyangZhou/pytorch-vsumm-reinforce.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O82o1HviLISz"
      },
      "source": [
        "!git clone https://github.com/li-plus/DSNet.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpV5snZhQ2WL"
      },
      "source": [
        "## VASNet\n",
        "\n",
        "* https://github.com/ok1zjf/VASNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWU_3Ru9S-1E"
      },
      "source": [
        "### Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH-JLYuLSVN0"
      },
      "source": [
        "!pip install ortools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qho9yDxnRQ4V"
      },
      "source": [
        "### Download dataset and model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG0WunRIQ__N"
      },
      "source": [
        "szRootDir = '/content/drive/MyDrive/0.Desktop/VSUM-Colab/VASNet' #Duy\n",
        "%cd $szRootDir \n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWNoQkhxQ42A"
      },
      "source": [
        "#!bash ./download.sh datasets_models_urls.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFRAAWRRRjoj"
      },
      "source": [
        "### Evaluation\n",
        "To evaluate all splits in ```./data/splits``` with corresponding trained models in ```./data/models``` \n",
        "run the following: \n",
        "```\n",
        "python3 main.py\n",
        "```\n",
        "\n",
        "For experiment saved in different than ```./data``` directory use parameter ```-o <directory_name>``` Results for \n",
        "the default split files and given hw/sw configuration are as follows:\n",
        "\n",
        "```\n",
        "\n",
        "---------------------------------------------------------\n",
        "  No   Split                                Mean F-score\n",
        "=========================================================\n",
        "  1    splits/tvsum_splits.json             61.428% \n",
        "  2    splits/summe_splits.json             49.631% \n",
        "  3    splits/tvsum_aug_splits.json         62.457% \n",
        "  4    splits/summe_aug_splits.json         51.11%  \n",
        "---------------------------------------------------------\n",
        "\n",
        "```\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxPe3hd-R0id"
      },
      "source": [
        "!python main.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oFMKc-3Tr1Y"
      },
      "source": [
        "### Training\n",
        "\n",
        "To train the VASNet on all split files in the ```./splits``` directory run this command:\n",
        "```\n",
        "python3 main.py --train\n",
        "```\n",
        "\n",
        "Results, including a copy of the split and python files, will be stored in ```./data``` directory. \n",
        "You can specify different directory with a parameter ```-o <directory_name>``` This is convenient if you \n",
        "are running a number of experiments and want to preserve the results and configuration. \n",
        "\n",
        "The final results will be recorded in ```./data/results.txt``` with corresponding models in \n",
        "the ```./data/models``` directory.    \n",
        "\n",
        "By default, the training is done with split files in ```./splits``` directory. These files were created \n",
        "with ```create_split.py```. For example, to create 5 fold split file for the SumMe dataset run the following command:  \n",
        "```\n",
        "python3 create_split.py -d datasets/eccv16_dataset_summe_google_pool5.h5 --save-dir splits --save-name summe_splits --num-splits 5\n",
        "```\n",
        "The split file will be saved as ```./splits/summe_splits.json```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXF5rkavTtKV"
      },
      "source": [
        "!python main.py --train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXuas_teU7q0"
      },
      "source": [
        "## DR-DSN pytorch-vsumm-reinforce\n",
        "\n",
        "* https://github.com/KaiyangZhou/pytorch-vsumm-reinforce"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl4d_YUBU_Bb"
      },
      "source": [
        "### Link to existing datasets - VASNet\n",
        "\n",
        "* https://www.cyberciti.biz/faq/creating-soft-link-or-symbolic-link/\n",
        "\n",
        "```\n",
        "$ ln -s {source-dir-name} {symbolic-dir-name}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SbJm_lmt5NG",
        "outputId": "2fbbe544-2eb6-4e66-92fa-e6437dcc895d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7gL4m8rVeXs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d603947-56d4-40d2-b967-4ec101e8e38b"
      },
      "source": [
        "#szRootDir = '/content/drive/MyDrive/0.Desktop/VSUM-Colab/pytorch-vsumm-reinforce' #Duy\n",
        "szRootDir = '/content/drive/MyDrive/VSum/Colab/pytorch-vsumm-reinforce' #An\n",
        "\n",
        "%cd $szRootDir \n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1UnHkRTf9TYt790JF-rSwz0LnpK9HeZ6E/Colab/pytorch-vsumm-reinforce\n",
            "/content/drive/.shortcut-targets-by-id/1UnHkRTf9TYt790JF-rSwz0LnpK9HeZ6E/Colab/pytorch-vsumm-reinforce\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOjUAa7HVk0g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "694ff5a0-e71b-4db8-b783-30eb25f0337b"
      },
      "source": [
        "szDatasetDirVASNet = szRootDir + '/../VASNet/datasets'\n",
        "!ls $szDatasetDirVASNet\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Copy of eccv16_dataset_ovp_google_pool5.h5'\n",
            "'Copy of eccv16_dataset_ovp_google_pool5.h5.custom'\n",
            "'Copy of eccv16_dataset_summe_google_pool5.h5'\n",
            "'Copy of eccv16_dataset_tvsum_google_pool5.h5'\n",
            "'Copy of eccv16_dataset_youtube_google_pool5.h5'\n",
            " eccv16_dataset_ovp_google_pool5.h5\n",
            " eccv16_dataset_ovp_google_pool5.h5.custom\n",
            " eccv16_dataset_summe_google_pool5.h5\n",
            " eccv16_dataset_tvsum_google_pool5.h5\n",
            " eccv16_dataset_youtube_google_pool5.h5\n",
            " readme.txt\n",
            " summe_splits.json\n",
            " tvsum_splits.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS6Cu5vBW2Rg"
      },
      "source": [
        "#!ln -s '/content/drive/MyDrive/0.Desktop/VSUM-Colab/VASNet/datasets' '/content/drive/MyDrive/0.Desktop/VSUM-Colab/pytorch-vsumm-reinforce/datasets'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DHrtRraXZ3X"
      },
      "source": [
        "### Make splits\n",
        "\n",
        "As a result, the dataset is randomly split for 5 times, which are saved as json file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0QpGIsRXWEF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1a12433-fddd-4a0d-fb52-2ccb6ab5550d"
      },
      "source": [
        "!python create_split.py -d datasets/eccv16_dataset_summe_google_pool5.h5 --save-dir datasets --save-name summe_splits  --num-splits 5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==========\n",
            "Args:Namespace(dataset='datasets/eccv16_dataset_summe_google_pool5.h5', num_splits=5, save_dir='datasets', save_name='summe_splits', train_percent=0.8)\n",
            "==========\n",
            "Goal: randomly split data for 5 times, 80.0% for training and the rest for testing\n",
            "Loading dataset from datasets/eccv16_dataset_summe_google_pool5.h5\n",
            "Split breakdown: # total videos 25. # train videos 20. # test videos 5\n",
            "Splits saved to datasets/summe_splits.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4xlob_KXwgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cfd753c-4070-4053-b267-da08fee3843d"
      },
      "source": [
        "!python create_split.py -d datasets/eccv16_dataset_tvsum_google_pool5.h5 --save-dir datasets --save-name tvsum_splits  --num-splits 5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==========\n",
            "Args:Namespace(dataset='datasets/eccv16_dataset_tvsum_google_pool5.h5', num_splits=5, save_dir='datasets', save_name='tvsum_splits', train_percent=0.8)\n",
            "==========\n",
            "Goal: randomly split data for 5 times, 80.0% for training and the rest for testing\n",
            "Loading dataset from datasets/eccv16_dataset_tvsum_google_pool5.h5\n",
            "Split breakdown: # total videos 50. # train videos 40. # test videos 10\n",
            "Splits saved to datasets/tvsum_splits.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qmPBbjoX6Ga"
      },
      "source": [
        "### Train\n",
        "\n",
        "```\n",
        "python main.py -d datasets/eccv16_dataset_summe_google_pool5.h5 -s datasets/summe_splits.json -m summe --gpu 0 --save-dir log/summe-split0 --split-id 0 --verbose\n",
        "```\n",
        "\n",
        "* Lỗitương thích Python2 và Python3: xrange trong vsum_tools.py và knapsack.py - đã đổi xrange thành range (https://stackoverflow.com/questions/17192158/nameerror-global-name-xrange-is-not-defined-in-python-3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9Pl7d3nYvA3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "641440e7-d089-4d1a-e3e4-74697669c999"
      },
      "source": [
        "!pwd\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1UnHkRTf9TYt790JF-rSwz0LnpK9HeZ6E/Colab/pytorch-vsumm-reinforce\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcQP0yCqYgk_"
      },
      "source": [
        "!python main.py -d datasets/eccv16_dataset_summe_google_pool5.h5 -s datasets/summe_splits.json -m summe --gpu 0 --save-dir log/summe-split0 --split-id 0 --verbose"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASdjEkuDX70V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0853c9d9-1034-4333-fa90-28ff62956142"
      },
      "source": [
        " !python main.py -d datasets/eccv16_dataset_tvsum_google_pool5.h5 -s datasets/tvsum_splits.json -m tvsum --gpu 0 --save-dir log/tvsum-split0 --split-id 0 --verbose"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==========\n",
            "Args:Namespace(beta=0.01, dataset='datasets/eccv16_dataset_tvsum_google_pool5.h5', evaluate=False, gamma=0.1, gpu='0', hidden_dim=256, input_dim=1024, lr=1e-05, max_epoch=60, metric='tvsum', num_episode=5, num_layers=1, resume='', rnn_cell='lstm', save_dir='log/tvsum-split0', save_results=False, seed=1, split='datasets/tvsum_splits.json', split_id=0, stepsize=30, use_cpu=False, verbose=True, weight_decay=1e-05)\n",
            "==========\n",
            "Currently using GPU 0\n",
            "Initialize dataset datasets/eccv16_dataset_tvsum_google_pool5.h5\n",
            "# total videos 50. # train videos 40. # test videos 10\n",
            "Initialize model\n",
            "Model size: 2.62605M\n",
            "==> Start training\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/content/drive/.shortcut-targets-by-id/1UnHkRTf9TYt790JF-rSwz0LnpK9HeZ6E/Colab/pytorch-vsumm-reinforce/rewards.py:47: UserWarning: This overload of addmm_ is deprecated:\n",
            "\taddmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddmm_(Tensor mat1, Tensor mat2, *, Number beta, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
            "  dist_mat.addmm_(1, -2, _seq, _seq.t())\n",
            "epoch 1/60\t reward 0.9140543586015699\t\n",
            "epoch 2/60\t reward 0.9142800322175025\t\n",
            "epoch 3/60\t reward 0.9140381100773812\t\n",
            "epoch 4/60\t reward 0.913535517156124\t\n",
            "epoch 5/60\t reward 0.913499111533165\t\n",
            "epoch 6/60\t reward 0.9135360115766525\t\n",
            "epoch 7/60\t reward 0.9131429976224898\t\n",
            "epoch 8/60\t reward 0.9131295925378801\t\n",
            "epoch 9/60\t reward 0.9137290018796922\t\n",
            "epoch 10/60\t reward 0.9131496807932855\t\n",
            "epoch 11/60\t reward 0.9137234252691269\t\n",
            "epoch 12/60\t reward 0.9127946189045906\t\n",
            "epoch 13/60\t reward 0.9135176628828049\t\n",
            "epoch 14/60\t reward 0.9136371222138406\t\n",
            "epoch 15/60\t reward 0.9139513891935348\t\n",
            "epoch 16/60\t reward 0.9137498620152474\t\n",
            "epoch 17/60\t reward 0.9135909634828568\t\n",
            "epoch 18/60\t reward 0.9139230275154112\t\n",
            "epoch 19/60\t reward 0.9140292814373969\t\n",
            "epoch 20/60\t reward 0.9141873627901077\t\n",
            "epoch 21/60\t reward 0.9138282972574234\t\n",
            "epoch 22/60\t reward 0.9138986188173295\t\n",
            "epoch 23/60\t reward 0.9142038041353227\t\n",
            "epoch 24/60\t reward 0.9139865335822106\t\n",
            "epoch 25/60\t reward 0.9141143724322319\t\n",
            "epoch 26/60\t reward 0.9145373538136482\t\n",
            "epoch 27/60\t reward 0.9143456050753593\t\n",
            "epoch 28/60\t reward 0.9140252801775933\t\n",
            "epoch 29/60\t reward 0.9142178082466126\t\n",
            "epoch 30/60\t reward 0.9153158205747605\t\n",
            "epoch 31/60\t reward 0.9142707037925721\t\n",
            "epoch 32/60\t reward 0.914885088801384\t\n",
            "epoch 33/60\t reward 0.9150215792655946\t\n",
            "epoch 34/60\t reward 0.9144790995121002\t\n",
            "epoch 35/60\t reward 0.9149068006873129\t\n",
            "epoch 36/60\t reward 0.9150371292233468\t\n",
            "epoch 37/60\t reward 0.9146192854642867\t\n",
            "epoch 38/60\t reward 0.9147753742337226\t\n",
            "epoch 39/60\t reward 0.9146464151144027\t\n",
            "epoch 40/60\t reward 0.9150936904549599\t\n",
            "epoch 41/60\t reward 0.915823161303997\t\n",
            "epoch 42/60\t reward 0.9146929413080216\t\n",
            "epoch 43/60\t reward 0.9148556408286094\t\n",
            "epoch 44/60\t reward 0.9152991619706153\t\n",
            "epoch 45/60\t reward 0.9156348964571952\t\n",
            "epoch 46/60\t reward 0.9156269398331643\t\n",
            "epoch 47/60\t reward 0.9148141953349114\t\n",
            "epoch 48/60\t reward 0.9145282146334648\t\n",
            "epoch 49/60\t reward 0.9158772519230844\t\n",
            "epoch 50/60\t reward 0.9146746310591698\t\n",
            "epoch 51/60\t reward 0.9156084540486334\t\n",
            "epoch 52/60\t reward 0.9157926407456397\t\n",
            "epoch 53/60\t reward 0.915620211660862\t\n",
            "epoch 54/60\t reward 0.9148333343863488\t\n",
            "epoch 55/60\t reward 0.9158503443002701\t\n",
            "epoch 56/60\t reward 0.9159576335549355\t\n",
            "epoch 57/60\t reward 0.91559172809124\t\n",
            "epoch 58/60\t reward 0.9166121834516525\t\n",
            "epoch 59/60\t reward 0.9158150425553323\t\n",
            "epoch 60/60\t reward 0.9164937621355056\t\n",
            "==> Test\n",
            "---  --------  -------\n",
            "No.  Video     F-score\n",
            "1    video_16  62.1%\n",
            "2    video_19  61.6%\n",
            "3    video_20  58.0%\n",
            "4    video_33  56.2%\n",
            "5    video_34  50.6%\n",
            "6    video_35  56.3%\n",
            "7    video_37  40.2%\n",
            "8    video_39  41.8%\n",
            "9    video_40  54.7%\n",
            "10   video_48  50.4%\n",
            "---  --------  -------\n",
            "Average F-score 53.2%\n",
            "Finished. Total elapsed time (h:m:s): 0:01:30\n",
            "Model saved to log/tvsum-split0/model_epoch60.pth.tar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MOEAzO1988L",
        "outputId": "510a2ccd-c38e-454f-eb7b-b69f7e547d18"
      },
      "source": [
        " !python main.py -d datasets/eccv16_dataset_tvsum_google_pool5.h5 -s datasets/tvsum_splits.json -m tvsum --gpu 0 --save-dir log/tvsum-split0 --split-id 0 --verbose --max-epoch 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==========\n",
            "Args:Namespace(beta=0.01, dataset='datasets/eccv16_dataset_tvsum_google_pool5.h5', evaluate=False, gamma=0.1, gpu='0', hidden_dim=256, input_dim=1024, lr=1e-05, max_epoch=2, metric='tvsum', num_episode=5, num_layers=1, resume='', rnn_cell='lstm', save_dir='log/tvsum-split0', save_results=False, seed=1, split='datasets/tvsum_splits.json', split_id=0, stepsize=30, use_cpu=False, verbose=True, weight_decay=1e-05)\n",
            "==========\n",
            "Currently using GPU 0\n",
            "Initialize dataset datasets/eccv16_dataset_tvsum_google_pool5.h5\n",
            "# total videos 50. # train videos 40. # test videos 10\n",
            "Initialize model\n",
            "Model size: 2.62605M\n",
            "==> Start training\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/content/drive/.shortcut-targets-by-id/1UnHkRTf9TYt790JF-rSwz0LnpK9HeZ6E/Colab/pytorch-vsumm-reinforce/rewards.py:47: UserWarning: This overload of addmm_ is deprecated:\n",
            "\taddmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddmm_(Tensor mat1, Tensor mat2, *, Number beta, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
            "  dist_mat.addmm_(1, -2, _seq, _seq.t())\n",
            "epoch 1/2\t reward 0.9137460970878601\t\n",
            "epoch 2/2\t reward 0.9134619992971421\t\n",
            "==> Test\n",
            "---  --------  -------\n",
            "No.  Video     F-score\n",
            "1    video_16  62.1%\n",
            "2    video_19  62.8%\n",
            "3    video_20  62.4%\n",
            "4    video_33  56.1%\n",
            "5    video_34  46.5%\n",
            "6    video_35  62.9%\n",
            "7    video_37  45.2%\n",
            "8    video_39  41.4%\n",
            "9    video_40  54.2%\n",
            "10   video_48  37.2%\n",
            "---  --------  -------\n",
            "Average F-score 53.1%\n",
            "Finished. Total elapsed time (h:m:s): 0:00:05\n",
            "Model saved to log/tvsum-split0/model_epoch2.pth.tar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK6paBjYryOg"
      },
      "source": [
        "### Debug Training (Hoang - An - Duy) - 15/04/2021\n",
        "\n",
        "*VSUM_CODE0: code mẫu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKSh-aazscB3"
      },
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import os.path as osp\n",
        "import argparse\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H43nQjQVsVp7"
      },
      "source": [
        "#VSUM_CODE0\n",
        "# Để tách code trong file main.py thành các cell - nhưng phải sử dụng các tham số của commandline\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import os.path as osp\n",
        "import argparse\n",
        "import sys\n",
        "\n",
        "parser = argparse.ArgumentParser(\"Pytorch code for unsupervised video summarization with REINFORCE\")\n",
        "parser = argparse.ArgumentParser(prog='main.py')\n",
        "# Dataset options\n",
        "parser.add_argument('-d', '--dataset', type=str, required=True, help=\"path to h5 dataset (required)\")\n",
        "parser.add_argument('-s', '--split', type=str, required=True, help=\"path to split file (required)\")\n",
        "parser.add_argument('--split-id', type=int, default=0, help=\"split index (default: 0)\")\n",
        "parser.add_argument('-m', '--metric', type=str, required=True, choices=['tvsum', 'summe'],\n",
        "                    help=\"evaluation metric ['tvsum', 'summe']\")\n",
        "# Model options\n",
        "parser.add_argument('--input-dim', type=int, default=1024, help=\"input dimension (default: 1024)\")\n",
        "parser.add_argument('--hidden-dim', type=int, default=256, help=\"hidden unit dimension of DSN (default: 256)\")\n",
        "parser.add_argument('--num-layers', type=int, default=1, help=\"number of RNN layers (default: 1)\")\n",
        "parser.add_argument('--rnn-cell', type=str, default='lstm', help=\"RNN cell type (default: lstm)\")\n",
        "# Optimization options\n",
        "parser.add_argument('--lr', type=float, default=1e-05, help=\"learning rate (default: 1e-05)\")\n",
        "parser.add_argument('--weight-decay', type=float, default=1e-05, help=\"weight decay rate (default: 1e-05)\")\n",
        "parser.add_argument('--max-epoch', type=int, default=60, help=\"maximum epoch for training (default: 60)\")\n",
        "parser.add_argument('--stepsize', type=int, default=30, help=\"how many steps to decay learning rate (default: 30)\")\n",
        "parser.add_argument('--gamma', type=float, default=0.1, help=\"learning rate decay (default: 0.1)\")\n",
        "parser.add_argument('--num-episode', type=int, default=5, help=\"number of episodes (default: 5)\")\n",
        "parser.add_argument('--beta', type=float, default=0.01, help=\"weight for summary length penalty term (default: 0.01)\")\n",
        "# Misc\n",
        "parser.add_argument('--seed', type=int, default=1, help=\"random seed (default: 1)\")\n",
        "parser.add_argument('--gpu', type=str, default='0', help=\"which gpu devices to use\")\n",
        "parser.add_argument('--use-cpu', action='store_true', help=\"use cpu device\")\n",
        "parser.add_argument('--evaluate', action='store_true', help=\"whether to do evaluation only\")\n",
        "parser.add_argument('--save-dir', type=str, default='log', help=\"path to save output (default: 'log/')\")\n",
        "parser.add_argument('--resume', type=str, default='', help=\"path to resume file\")\n",
        "parser.add_argument('--verbose', action='store_true', help=\"whether to show detailed test results\")\n",
        "parser.add_argument('--save-results', action='store_true', help=\"whether to save output results\")\n",
        "\n",
        "sys.argv = ['main.py'] + '-d datasets/eccv16_dataset_tvsum_google_pool5.h5 -s datasets/tvsum_splits.json -m tvsum --gpu 0 --save-dir log/tvsum-split0 --split-id 0 --verbose'.split()\n",
        "args = parser.parse_args()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcwHwIAtwEhu",
        "outputId": "6cbd91d8-493d-4703-b3aa-fa26e2422852"
      },
      "source": [
        "#VSUM_CODE0\n",
        "# Để kiểm tra có sử dụng GPU backend không\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.distributions import Bernoulli\n",
        "\n",
        "print(torch.__version__)\n",
        "torch.manual_seed(args.seed)\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
        "use_gpu = torch.cuda.is_available()\n",
        "if args.use_cpu: use_gpu = False\n",
        "\n",
        "if use_gpu:\n",
        "  print(\"Currently using GPU {}\".format(args.gpu))\n",
        "  cudnn.benchmark = True\n",
        "  torch.cuda.manual_seed_all(args.seed)\n",
        "else:\n",
        "  print(\"Currently using CPU\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8.1+cu101\n",
            "Currently using GPU 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc6I1TljsOGi"
      },
      "source": [
        "import h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LhAYT-rr7IT",
        "outputId": "7b479b92-8984-4156-93cb-4fc4aa592971"
      },
      "source": [
        "print(\"Initialize dataset {}\".format(args.dataset))\n",
        "dataset = h5py.File(args.dataset, 'r')\n",
        "num_videos = len(dataset.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialize dataset datasets/eccv16_dataset_tvsum_google_pool5.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aprNfe5LwkaL",
        "outputId": "50eae314-6749-42f9-84b1-93f6b0b13de4"
      },
      "source": [
        "from utils import Logger, read_json, write_json, save_checkpoint\n",
        "\n",
        "splits = read_json(args.split)\n",
        "assert args.split_id < len(splits), \"split_id (got {}) exceeds {}\".format(args.split_id, len(splits))\n",
        "split = splits[args.split_id]\n",
        "train_keys = split['train_keys']\n",
        "test_keys = split['test_keys']\n",
        "print(\"# total videos {}. # train videos {}. # test videos {}\".format(num_videos, len(train_keys), len(test_keys)))\n",
        "\n",
        "print(train_keys)\n",
        "print(test_keys)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# total videos 50. # train videos 40. # test videos 10\n",
            "['video_1', 'video_10', 'video_11', 'video_12', 'video_13', 'video_14', 'video_15', 'video_17', 'video_18', 'video_2', 'video_21', 'video_22', 'video_23', 'video_24', 'video_25', 'video_26', 'video_27', 'video_28', 'video_29', 'video_3', 'video_30', 'video_31', 'video_32', 'video_36', 'video_38', 'video_4', 'video_41', 'video_42', 'video_43', 'video_44', 'video_45', 'video_46', 'video_47', 'video_49', 'video_5', 'video_50', 'video_6', 'video_7', 'video_8', 'video_9']\n",
            "['video_16', 'video_19', 'video_20', 'video_33', 'video_34', 'video_35', 'video_37', 'video_39', 'video_40', 'video_48']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOG3evvixTH7",
        "outputId": "26019864-fe12-482d-eee0-e70ab07e1be0"
      },
      "source": [
        "from models import *\n",
        "\n",
        "print(\"Initialize model\")\n",
        "model = DSN(in_dim=args.input_dim, hid_dim=args.hidden_dim, num_layers=args.num_layers, cell=args.rnn_cell)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialize model\n",
            "DSN(\n",
            "  (rnn): LSTM(1024, 256, batch_first=True, bidirectional=True)\n",
            "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDRbHfobyQzb"
      },
      "source": [
        "#VSUM_CODE0\n",
        "# Rã DSN ra\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlRggaRf4nCz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65f47aae-03bc-4eab-d6e7-d6ff71b6105d"
      },
      "source": [
        "    import time\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "    if args.stepsize > 0:\n",
        "        scheduler = lr_scheduler.StepLR(optimizer, step_size=args.stepsize, gamma=args.gamma)\n",
        "\n",
        "    if args.resume:\n",
        "        print(\"Loading checkpoint from '{}'\".format(args.resume))\n",
        "        checkpoint = torch.load(args.resume)\n",
        "        model.load_state_dict(checkpoint)\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "\n",
        "    if use_gpu:\n",
        "        model = nn.DataParallel(model).cuda()\n",
        "\n",
        "    if args.evaluate:\n",
        "        print(\"Evaluate only\")\n",
        "        evaluate(model, dataset, test_keys, use_gpu)\n",
        "        exit()\n",
        "\n",
        "    print(\"==> Start training\")\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    baselines = {key: 0. for key in train_keys} # baseline rewards for videos\n",
        "    reward_writers = {key: [] for key in train_keys} # record reward changes for each video\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Start training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4EuIANO5ErH",
        "outputId": "b0fdb798-4c8c-406b-bf7e-f46928dc7617"
      },
      "source": [
        "import numpy as np\n",
        "from utils import Logger, read_json, write_json, save_checkpoint\n",
        "from models import *\n",
        "from rewards import compute_reward\n",
        "import vsum_tools\n",
        "\n",
        "# for epoch in range(start_epoch, args.max_epoch):\n",
        "for epoch in range(start_epoch, start_epoch + 1):\n",
        "        idxs = np.arange(len(train_keys))\n",
        "        np.random.shuffle(idxs) # shuffle indices\n",
        "\n",
        "        for idx in idxs:\n",
        "            key = train_keys[idx]\n",
        "            seq = dataset[key]['features'][...] # sequence of features, (seq_len, dim)\n",
        "            seq = torch.from_numpy(seq).unsqueeze(0) # input shape (1, seq_len, dim)\n",
        "            if use_gpu: seq = seq.cuda()\n",
        "            probs = model(seq) # output shape (1, seq_len, 1)\n",
        "\n",
        "            cost = args.beta * (probs.mean() - 0.5)**2 # minimize summary length penalty term [Eq.11]\n",
        "            m = Bernoulli(probs)\n",
        "            epis_rewards = []\n",
        "            for _ in range(args.num_episode):\n",
        "                actions = m.sample()\n",
        "                log_probs = m.log_prob(actions)\n",
        "                reward = compute_reward(seq, actions, use_gpu=use_gpu)\n",
        "                expected_reward = log_probs.mean() * (reward - baselines[key])\n",
        "                cost -= expected_reward # minimize negative expected reward\n",
        "                epis_rewards.append(reward.item())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            cost.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "            optimizer.step()\n",
        "            baselines[key] = 0.9 * baselines[key] + 0.1 * np.mean(epis_rewards) # update baseline reward via moving average\n",
        "            reward_writers[key].append(np.mean(epis_rewards))\n",
        "\n",
        "        epoch_reward = np.mean([reward_writers[key][epoch] for key in train_keys])\n",
        "        print(\"epoch {}/{}\\t reward {}\\t\".format(epoch+1, args.max_epoch, epoch_reward))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/content/drive/.shortcut-targets-by-id/1UnHkRTf9TYt790JF-rSwz0LnpK9HeZ6E/Colab/pytorch-vsumm-reinforce/rewards.py:47: UserWarning: This overload of addmm_ is deprecated:\n",
            "\taddmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddmm_(Tensor mat1, Tensor mat2, *, Number beta, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
            "  dist_mat.addmm_(1, -2, _seq, _seq.t())\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1/60\t reward 0.9136160776019097\t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6vDtYkSdnXJ"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrGlUUX3dxSA"
      },
      "source": [
        "!python main.py -d datasets/eccv16_dataset_tvsum_google_pool5.h5 -s datasets/tvsum_splits.json -m tvsum --gpu 0 --save-dir log/tvsum-split0 --split-id 0 --evaluate --resume log/tvsum-split0/model_epoch60.pth.tar --verbose --save-results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdZBK1CPePDk"
      },
      "source": [
        "!python visualize_results.py -p log/tvsum-split0/result.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTE0MFwke64Z"
      },
      "source": [
        "!python parse_log.py -p log/tvsum-split0/log_train.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1blUeIMfs0t"
      },
      "source": [
        "## DSNet\n",
        "\n",
        "* https://github.com/li-plus/DSNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzVb1IuJfvvz"
      },
      "source": [
        "### Link to existing datasets - VASNet\n",
        "\n",
        "* https://www.cyberciti.biz/faq/creating-soft-link-or-symbolic-link/\n",
        "\n",
        "```\n",
        "$ ln -s {source-dir-name} {symbolic-dir-name}\n",
        "```\n",
        "\n",
        "Now the datasets structure should look like\n",
        "\n",
        "```\n",
        "DSNet\n",
        "└── datasets/\n",
        "    ├── eccv16_dataset_ovp_google_pool5.h5\n",
        "    ├── eccv16_dataset_summe_google_pool5.h5\n",
        "    ├── eccv16_dataset_tvsum_google_pool5.h5\n",
        "    ├── eccv16_dataset_youtube_google_pool5.h5\n",
        "    └── readme.txt\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4r3U8OMZgx-c"
      },
      "source": [
        "szRootDir = '/content/drive/MyDrive/0.Desktop/VSUM-Colab/DSNet' #Duy\n",
        "%cd $szRootDir \n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTnwhILPg_7Z"
      },
      "source": [
        "#!ln -s '/content/drive/MyDrive/0.Desktop/VSUM-Colab/VASNet/datasets' '/content/drive/MyDrive/0.Desktop/VSUM-Colab/DSNet/datasets'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLo8FKSHhbJ8"
      },
      "source": [
        "### Pre-trained Models\n",
        "\n",
        "Our pre-trained models are now available online. You may download them for evaluation, or you may skip this section and train a new one from scratch.\n",
        "\n",
        "```sh\n",
        "mkdir -p models && cd models\n",
        "# anchor-based model\n",
        "wget https://www.dropbox.com/s/0jwn4c1ccjjysrz/pretrain_ab_basic.zip\n",
        "unzip pretrain_ab_basic.zip\n",
        "# anchor-free model\n",
        "wget https://www.dropbox.com/s/2hjngmb0f97nxj0/pretrain_af_basic.zip\n",
        "unzip pretrain_af_basic.zip\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUjkS6yVhv_I"
      },
      "source": [
        "!mkdir -p models \n",
        "%cd models\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfBFt-vXh7Rq"
      },
      "source": [
        "!wget https://www.dropbox.com/s/0jwn4c1ccjjysrz/pretrain_ab_basic.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFT6iLhLh83R"
      },
      "source": [
        "!unzip pretrain_ab_basic.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RitEXGediIjS"
      },
      "source": [
        "!wget https://www.dropbox.com/s/2hjngmb0f97nxj0/pretrain_af_basic.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXamOJ_piJha"
      },
      "source": [
        "!unzip pretrain_af_basic.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNUiIkKmhLZT"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "To evaluate our pre-trained models, type:\n",
        "\n",
        "```sh\n",
        "# evaluate anchor-based model\n",
        "python evaluate.py anchor-based --model-dir ../models/pretrain_ab_basic/ --splits ../splits/tvsum.yml ../splits/summe.yml\n",
        "# evaluate anchor-free model\n",
        "python evaluate.py anchor-free --model-dir ../models/pretrain_af_basic/ --splits ../splits/tvsum.yml ../splits/summe.yml --nms-thresh 0.4\n",
        "```\n",
        "\n",
        "If everything works fine, you will get similar F-score results as follows.\n",
        "\n",
        "|              | TVSum | SumMe |\n",
        "| ------------ | ----- | ----- |\n",
        "| Anchor-based | 62.05 | 50.19 |\n",
        "| Anchor-free  | 61.86 | 51.18 |\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXG7mQ1GibMU"
      },
      "source": [
        "szRootDir = '/content/drive/MyDrive/0.Desktop/VSUM-Colab/DSNet' #Duy\n",
        "%cd $szRootDir \n",
        "!pwd\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_eBybnMi1DK"
      },
      "source": [
        "import os\n",
        " \n",
        "print(\"pwd=%s\" % os.getcwd()) # old style formating\n",
        "\n",
        "# In courtersy of : https://stackoverflow.com/questions/49264194/import-py-file-in-another-directory-in-jupyter-notebook\n",
        "import sys  \n",
        "sys.path.insert(0, szRootDir + \"/src/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upRPulUCjCMN"
      },
      "source": [
        "%cd $szRootDir/src\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GNS25DfiXZX"
      },
      "source": [
        "!python evaluate.py anchor-based --model-dir ../models/pretrain_ab_basic/ --splits ../splits/tvsum.yml ../splits/summe.yml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXpEkNkljSul"
      },
      "source": [
        "!python evaluate.py anchor-free --model-dir ../models/pretrain_af_basic/ --splits ../splits/tvsum.yml ../splits/summe.yml --nms-thresh 0.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvHlce3WjgcV"
      },
      "source": [
        "### Training\n",
        "\n",
        "#### Anchor-based\n",
        "\n",
        "To train anchor-based attention model on TVSum and SumMe datasets with canonical settings, run\n",
        "\n",
        "```sh\n",
        "python train.py anchor-based --model-dir ../models/ab_basic --splits ../splits/tvsum.yml ../splits/summe.yml\n",
        "```\n",
        "\n",
        "To train on augmented and transfer datasets, run\n",
        "\n",
        "```sh\n",
        "python train.py anchor-based --model-dir ../models/ab_tvsum_aug/ --splits ../splits/tvsum_aug.yml\n",
        "python train.py anchor-based --model-dir ../models/ab_summe_aug/ --splits ../splits/summe_aug.yml\n",
        "python train.py anchor-based --model-dir ../models/ab_tvsum_trans/ --splits ../splits/tvsum_trans.yml\n",
        "python train.py anchor-based --model-dir ../models/ab_summe_trans/ --splits ../splits/summe_trans.yml\n",
        "```\n",
        "\n",
        "To train with LSTM, Bi-LSTM or GCN feature extractor, specify the `--base-model` argument as `lstm`, `bilstm`, or `gcn`. For example,\n",
        "\n",
        "```sh\n",
        "python train.py anchor-based --model-dir ../models/ab_basic --splits ../splits/tvsum.yml ../splits/summe.yml --base-model lstm\n",
        "```\n",
        "\n",
        "#### Anchor-free\n",
        "\n",
        "Much similar to anchor-based models, to train on canonical TVSum and SumMe, run\n",
        "\n",
        "```sh\n",
        "python train.py anchor-free --model-dir ../models/af_basic --splits ../splits/tvsum.yml ../splits/summe.yml --nms-thresh 0.4\n",
        "```\n",
        "\n",
        "Note that NMS threshold is set to 0.4 for anchor-free models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF7Gk5EOjkzx"
      },
      "source": [
        "!python train.py anchor-based --model-dir ../models/ab_basic --splits ../splits/tvsum.yml ../splits/summe.yml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuVDa9eOjwVH"
      },
      "source": [
        "!python train.py anchor-based --model-dir ../models/ab_basic --splits ../splits/tvsum.yml ../splits/summe.yml --base-model lstm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuT2lJAHjzM9"
      },
      "source": [
        "!python train.py anchor-free --model-dir ../models/af_basic --splits ../splits/tvsum.yml ../splits/summe.yml --nms-thresh 0.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuOelH0uj9aI"
      },
      "source": [
        "### Generating Shots with KTS\n",
        "\n",
        "Based on the public datasets provided by [DR-DSN](https://github.com/KaiyangZhou/pytorch-vsumm-reinforce), we apply [KTS](https://github.com/pathak22/videoseg/tree/master/lib/kts) algorithm to generate video shots for OVP and YouTube datasets. Note that the pre-processed datasets already contain these video shots. To re-generate video shots, run\n",
        "\n",
        "```sh\n",
        "python make_shots.py --dataset ../datasets/eccv16_dataset_ovp_google_pool5.h5\n",
        "python make_shots.py --dataset ../datasets/eccv16_dataset_youtube_google_pool5.h5\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4JlxpmbkC33"
      },
      "source": [
        "!python make_shots.py --dataset ../datasets/eccv16_dataset_ovp_google_pool5.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tboNp2SJkoH3"
      },
      "source": [
        "##dppLSTM\n",
        "\n",
        "* https://github.com/kezhang-cs/Video-Summarization-with-LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3349tcacmY81"
      },
      "source": [
        "### Link to existing datasets - VASNet\n",
        "\n",
        "* gốc dùng thư mục data - chuyển thành datasets cho nhất quán (sửa code)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccqGNk6qmdJY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6aba869-173a-41be-eef0-2f05a6ed0980"
      },
      "source": [
        "szRootDir = '/content/drive/MyDrive/0.Desktop/VSUM-Colab/Video-Summarization-with-LSTM' #Duy\n",
        "szRootDir = '/content/drive/MyDrive/VSum/Colab/Video-Summarization-with-LSTM' #An\n",
        "%cd $szRootDir \n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1UnHkRTf9TYt790JF-rSwz0LnpK9HeZ6E/Colab/Video-Summarization-with-LSTM\n",
            "/content/drive/.shortcut-targets-by-id/1UnHkRTf9TYt790JF-rSwz0LnpK9HeZ6E/Colab/Video-Summarization-with-LSTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3McB12XnU7R"
      },
      "source": [
        "#!ln -s '/content/drive/MyDrive/0.Desktop/VSUM-Colab/VASNet/datasets' '/content/drive/MyDrive/0.Desktop/VSUM-Colab/Video-Summarization-with-LSTM/datasets'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TBE6LJppT2u"
      },
      "source": [
        "### dppLSTM for video summarization\n",
        "We have enclosed pre-trained models in the *./model* directory\n",
        "download the model and run the following commands:\n",
        "\n",
        "Download the pre-trained models and unzip it to *./models* and run the following commands:\n",
        "```\n",
        "cd ./codes\n",
        "THEANO_FLAGS=device=gpu0,floatX=float32 python dppLSTM_main.py \n",
        "```\n",
        "\n",
        "This will automatically run summarization on the video data using pre-trained model, and save the results in *./res_LSTM/* as **dppLSTM_\\$DATASET\\$_2_inference.h5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk77GBwEpbnv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63e4c448-f828-4013-e1d9-452da824b754"
      },
      "source": [
        "import os\n",
        " \n",
        "print(\"pwd=%s\" % os.getcwd()) # old style formating\n",
        "\n",
        "# In courtersy of : https://stackoverflow.com/questions/49264194/import-py-file-in-another-directory-in-jupyter-notebook\n",
        "import sys  \n",
        "sys.path.insert(1, szRootDir + \"/codes/\")\n",
        "sys.path.insert(0, szRootDir + \"/codes/layers/\")\n",
        "print(sys.path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pwd=/content/drive/.shortcut-targets-by-id/1UnHkRTf9TYt790JF-rSwz0LnpK9HeZ6E/Colab/Video-Summarization-with-LSTM\n",
            "['/content/drive/MyDrive/VSum/Colab/Video-Summarization-with-LSTM/codes/layers/', '/content/drive/MyDrive/0.Desktop/VSUM-Colab/pytorch-vsumm-reinforce/codes/layers/', '/content/drive/MyDrive/VSum/Colab/Video-Summarization-with-LSTM/codes/', '', '/content/drive/MyDrive/0.Desktop/VSUM-Colab/pytorch-vsumm-reinforce/codes/', '/content', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.7/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnwcfcY-pq1I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7fefd7d-2f92-42fe-e386-1bd41ca6f69e"
      },
      "source": [
        "%cd $szRootDir/codes\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1UnHkRTf9TYt790JF-rSwz0LnpK9HeZ6E/Colab/Video-Summarization-with-LSTM/codes\n",
            "/content/drive/.shortcut-targets-by-id/1UnHkRTf9TYt790JF-rSwz0LnpK9HeZ6E/Colab/Video-Summarization-with-LSTM/codes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr45VelmqFfo"
      },
      "source": [
        "Sửa một số lỗi tương thích Python2 và Python3\n",
        "* print\n",
        "* summ_dppLSTM.py - from layers.mlp import mlp\n",
        "* data_loader.py\n",
        "* dppLSTM_main.py data_loader.load_data(data_dir = '../datasets/, file_name = data_dir + '/eccv16_' + dataset + '_google_p5.h5'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEPKUNETqDvE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "632c8a7d-67a0-4ba8-e581-4547242fb0f6"
      },
      "source": [
        "!python dppLSTM_main.py "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "... loading data\n",
            "../datasets/eccv16_dataset_ovp_google_pool5.h5\n",
            "<HDF5 file \"eccv16_dataset_ovp_google_pool5.h5\" (mode r)>\n",
            "Traceback (most recent call last):\n",
            "  File \"dppLSTM_main.py\", line 76, in <module>\n",
            "    train_set, val_set, val_idx, test_set, te_idx = data_loader.load_data(data_dir = '../datasets', dataset_testing = dataset_testing, model_type = model_type)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1UnHkRTf9TYt790JF-rSwz0LnpK9HeZ6E/Colab/Video-Summarization-with-LSTM/codes/tools/data_loader.py\", line 14, in load_data\n",
            "    [feature, label, weight] = load_dataset_h5(data_dir, 'ovp', model_type)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1UnHkRTf9TYt790JF-rSwz0LnpK9HeZ6E/Colab/Video-Summarization-with-LSTM/codes/tools/data_loader.py\", line 115, in load_dataset_h5\n",
            "    vid_ord = numpy.sort(numpy.array(f['/ord']).astype('int32').flatten())\n",
            "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/h5py/_hl/group.py\", line 264, in __getitem__\n",
            "    oid = h5o.open(self.id, self._e(name), lapl=self._lapl)\n",
            "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/h5o.pyx\", line 190, in h5py.h5o.open\n",
            "KeyError: \"Unable to open object (object 'ord' doesn't exist)\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Au6nxWxwo-5"
      },
      "source": [
        "!ls ../datasets/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rg4Qp9sU2773",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46af85d2-2734-4d7f-822f-0c465979e3bd"
      },
      "source": [
        "!ls ../datasets/eccv16_dataset_ovp_google_pool*"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "../datasets/eccv16_dataset_ovp_google_pool5.h5\n",
            "../datasets/eccv16_dataset_ovp_google_pool5.h5.custom\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5thaegd4k4C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "outputId": "003016ad-19ac-4355-d2bd-6580cc1447f2"
      },
      "source": [
        "import h5py\n",
        "file_name = szRootDir + '/datasets/eccv16_dataset_ovp_google_pool5.h5'\n",
        "print(file_name)\n",
        "f = h5py.File(file_name, 'r')\n",
        "print(list(f.keys())[0])\n",
        "print(f['video_1'].keys())\n",
        "print(f['/fea'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/VSum/Colab/Video-Summarization-with-LSTM/datasets/eccv16_dataset_ovp_google_pool5.h5\n",
            "video_1\n",
            "<KeysViewHDF5 ['features', 'gtscore', 'gtsummary']>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-70de58384c0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'video_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'/fea'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0moid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0motype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Unable to open object (object 'fea' doesn't exist)\""
          ]
        }
      ]
    }
  ]
}