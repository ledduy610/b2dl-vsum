{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VSUM.VASNet-Revision.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPkTWz3OHwSOYl2v2as2y9U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ledduy610/b2dl-vsum/blob/main/VSUM_VASNet_Revision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsWMwyqTTSXS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR8b2Mq_7K_y"
      },
      "source": [
        "#VASNet Run in Notebook\n",
        "\n",
        "* Chỉnh lại VASNet để chạy cho các feature mới như InceptionV3 (2048-d) (GoogleNet là 1024-d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crGJhM2I-zKK"
      },
      "source": [
        "##Helper py **file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBSYwmXPxu3z"
      },
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import time\n",
        "import glob\n",
        "import random\n",
        "import argparse\n",
        "import h5py\n",
        "import json\n",
        "import torch.nn.init as init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTh2Spo8-uUH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "bd74b4d7-0d97-4362-a26f-0785ab9c815a"
      },
      "source": [
        "!pip install ortools\n",
        "!pip install knapsack\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ortools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/bd/75277072925d687aa35a6ea9e23e81a7f6b7c980b2a80949c5b9a3f98c79/ortools-9.0.9048-cp37-cp37m-manylinux1_x86_64.whl (14.4MB)\n",
            "\u001b[K     |████████████████████████████████| 14.4MB 213kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.11 in /usr/local/lib/python3.7/dist-packages (from ortools) (0.12.0)\n",
            "Collecting protobuf>=3.15.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/72/05ec80a16a85d9c0e69020ab731b1dafdf2fee591b30811c6b63ec447afe/protobuf-3.17.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 42.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.11->ortools) (1.15.0)\n",
            "Installing collected packages: protobuf, ortools\n",
            "  Found existing installation: protobuf 3.12.4\n",
            "    Uninstalling protobuf-3.12.4:\n",
            "      Successfully uninstalled protobuf-3.12.4\n",
            "Successfully installed ortools-9.0.9048 protobuf-3.17.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting knapsack\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/0ab665722f73befb7a6daca98d79026480bbfa11c49b326cfa0d8f4f5951/knapsack-0.0.7-py3-none-any.whl\n",
            "Installing collected packages: knapsack\n",
            "Successfully installed knapsack-0.0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7tYkMMWqHnE"
      },
      "source": [
        "###vsum_tools.py\n",
        "Verbatim pasted, along with knapsack.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCotAgVVqKir",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "784f11ee-7c5e-497d-aad2-bf4a08b77b6a"
      },
      "source": [
        "''''\n",
        "Courtesy of KaiyangZhou\n",
        "https://github.com/KaiyangZhou/pytorch-vsumm-reinforce\n",
        "\n",
        "@article{zhou2017reinforcevsumm,\n",
        "   title={Deep Reinforcement Learning for Unsupervised Video Summarization with Diversity-Representativeness Reward},\n",
        "   author={Zhou, Kaiyang and Qiao, Yu and Xiang, Tao},\n",
        "   journal={arXiv:1801.00054},\n",
        "   year={2017}\n",
        "}\n",
        "\n",
        "Modifications by Jiri Fajtl\n",
        "- knapsack replaced with knapsack_ortools\n",
        "- added evaluate_user_summaries() for user summaries ground truth evaluation\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# A Dynamic Programming based Python Program for 0-1 Knapsack problem\n",
        "# Returns the maximum value that can be put in a knapsack of capacity W\n",
        "import numpy as np\n",
        "from ortools.algorithms import pywrapknapsack_solver\n",
        "\n",
        "\n",
        "def knapsack(W, wt, val, n):\n",
        "    K = [[0 for x in range(W+1)] for x in range(n+1)]\n",
        "\n",
        "    # Build table K[][] in bottom up manner\n",
        "    for i in range(n+1):\n",
        "        for w in range(W+1):\n",
        "            if i==0 or w==0:\n",
        "                K[i][w] = 0\n",
        "            elif wt[i-1] <= w:\n",
        "                K[i][w] = max(val[i-1] + K[i-1][w-wt[i-1]],  K[i-1][w])\n",
        "            else:\n",
        "                K[i][w] = K[i-1][w]\n",
        "\n",
        "\n",
        "    best = K[n][W]\n",
        "\n",
        "    amount = np.zeros(n)\n",
        "    a = best\n",
        "    j = n\n",
        "    Y = W\n",
        "\n",
        "    # j = j + 1;\n",
        "    #\n",
        "    # amount(j) = 1;\n",
        "    # Y = Y - weights(j);\n",
        "    # j = j - 1;\n",
        "    # a = A(j + 1, Y + 1);\n",
        "\n",
        "    while a > 0:\n",
        "       while K[j][Y] == a:\n",
        "           j = j - 1\n",
        "\n",
        "       j = j + 1\n",
        "       amount[j-1] = 1\n",
        "       Y = Y - wt[j-1]\n",
        "       j = j - 1\n",
        "       a = K[j][Y]\n",
        "\n",
        "    return amount\n",
        "\n",
        "\n",
        "def test_knapsack():\n",
        "    weights = [1 ,1 ,1, 1 ,2 ,2 ,3]\n",
        "    values  = [1 ,1 ,2 ,3, 1, 3 ,5]\n",
        "    best = 13\n",
        "    print(knapsack(7, weights, values, 7))\n",
        "\n",
        "#===========================================\n",
        "'''\n",
        "------------------------------------------------\n",
        "Use dynamic programming (DP) to solve 0/1 knapsack problem\n",
        "Time complexity: O(nW), where n is number of items and W is capacity\n",
        "\n",
        "Author: Kaiyang Zhou\n",
        "Website: https://kaiyangzhou.github.io/\n",
        "------------------------------------------------\n",
        "knapsack_dp(values,weights,n_items,capacity,return_all=False)\n",
        "\n",
        "Input arguments:\n",
        "  1. values: a list of numbers in either int or float, specifying the values of items\n",
        "  2. weights: a list of int numbers specifying weights of items\n",
        "  3. n_items: an int number indicating number of items\n",
        "  4. capacity: an int number indicating the knapsack capacity\n",
        "  5. return_all: whether return all info, defaulty is False (optional)\n",
        "\n",
        "Return:\n",
        "  1. picks: a list of numbers storing the positions of selected items\n",
        "  2. max_val: maximum value (optional)\n",
        "------------------------------------------------\n",
        "'''\n",
        "def knapsack_dp(values,weights,n_items,capacity,return_all=False):\n",
        "    check_inputs(values,weights,n_items,capacity)\n",
        "\n",
        "    table = np.zeros((n_items+1,capacity+1),dtype=np.float32)\n",
        "    keep = np.zeros((n_items+1,capacity+1),dtype=np.float32)\n",
        "\n",
        "    for i in range(1,n_items+1):\n",
        "        for w in range(0,capacity+1):\n",
        "            wi = weights[i-1] # weight of current item\n",
        "            vi = values[i-1] # value of current item\n",
        "            if (wi <= w) and (vi + table[i-1,w-wi] > table[i-1,w]):\n",
        "                table[i,w] = vi + table[i-1,w-wi]\n",
        "                keep[i,w] = 1\n",
        "            else:\n",
        "                table[i,w] = table[i-1,w]\n",
        "\n",
        "    picks = []\n",
        "    K = capacity\n",
        "\n",
        "    for i in range(n_items,0,-1):\n",
        "        if keep[i,K] == 1:\n",
        "            picks.append(i)\n",
        "            K -= weights[i-1]\n",
        "\n",
        "    picks.sort()\n",
        "    picks = [x-1 for x in picks] # change to 0-index\n",
        "\n",
        "    if return_all:\n",
        "        max_val = table[n_items,capacity]\n",
        "        return picks,max_val\n",
        "    return picks\n",
        "\n",
        "def check_inputs(values,weights,n_items,capacity):\n",
        "    # check variable type\n",
        "    assert(isinstance(values,list))\n",
        "    assert(isinstance(weights,list))\n",
        "    assert(isinstance(n_items,int))\n",
        "    assert(isinstance(capacity,int))\n",
        "    # check value type\n",
        "    assert(all(isinstance(val,int) or isinstance(val,float) for val in values))\n",
        "    assert(all(isinstance(val,int) for val in weights))\n",
        "    # check validity of value\n",
        "    assert(all(val >= 0 for val in weights))\n",
        "    assert(n_items > 0)\n",
        "    assert(capacity > 0)\n",
        "\n",
        "def test_knapsack_dp():\n",
        "    values = [2,3,4]\n",
        "    weights = [1,2,3]\n",
        "    n_items = 3\n",
        "    capacity = 3\n",
        "    picks = knapsack_dp(values,weights,n_items,capacity)\n",
        "    print (picks)\n",
        "\n",
        "\n",
        "\n",
        "osolver = pywrapknapsack_solver.KnapsackSolver(\n",
        "    # pywrapknapsack_solver.KnapsackSolver.KNAPSACK_MULTIDIMENSION_BRANCH_AND_BOUND_SOLVER,\n",
        "    pywrapknapsack_solver.KnapsackSolver.KNAPSACK_DYNAMIC_PROGRAMMING_SOLVER,\n",
        "    'test')\n",
        "\n",
        "def knapsack_ortools(values, weights, items, capacity ):\n",
        "    scale = 1000\n",
        "    values = np.array(values)\n",
        "    weights = np.array(weights)\n",
        "    values = (values * scale).astype(np.int)\n",
        "    weights = (weights).astype(np.int)\n",
        "    capacity = capacity\n",
        "\n",
        "    osolver.Init(values.tolist(), [weights.tolist()], [capacity])\n",
        "    computed_value = osolver.Solve()\n",
        "    packed_items = [x for x in range(0, len(weights))\n",
        "                    if osolver.BestSolutionContains(x)]\n",
        "\n",
        "    return packed_items\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_knapsack_dp()\n",
        "    test_knapsack()\n",
        "\n",
        "\n",
        "import math\n",
        "\n",
        "\n",
        "def generate_summary(ypred, cps, n_frames, nfps, positions, proportion=0.15, method='knapsack'):\n",
        "    \"\"\"Generate keyshot-based video summary i.e. a binary vector.\n",
        "    Args:\n",
        "    ---------------------------------------------\n",
        "    - ypred: predicted importance scores.\n",
        "    - cps: change points, 2D matrix, each row contains a segment.\n",
        "    - n_frames: original number of frames.\n",
        "    - nfps: number of frames per segment.\n",
        "    - positions: positions of subsampled frames in the original video.\n",
        "    - proportion: length of video summary (compared to original video length).\n",
        "    - method: defines how shots are selected, ['knapsack', 'rank'].\n",
        "    \"\"\"\n",
        "    n_segs = cps.shape[0]\n",
        "    frame_scores = np.zeros((n_frames), dtype=np.float32)\n",
        "    if positions.dtype != int:\n",
        "        positions = positions.astype(np.int32)\n",
        "    if positions[-1] != n_frames:\n",
        "        positions = np.concatenate([positions, [n_frames]])\n",
        "    for i in range(len(positions) - 1):\n",
        "        pos_left, pos_right = positions[i], positions[i+1]\n",
        "        if i == len(ypred):\n",
        "            frame_scores[pos_left:pos_right] = 0\n",
        "        else:\n",
        "            frame_scores[pos_left:pos_right] = ypred[i]\n",
        "\n",
        "    seg_score = []\n",
        "    for seg_idx in range(n_segs):\n",
        "        start, end = int(cps[seg_idx,0]), int(cps[seg_idx,1]+1)\n",
        "        scores = frame_scores[start:end]\n",
        "        seg_score.append(float(scores.mean()))\n",
        "\n",
        "    limits = int(math.floor(n_frames * proportion))\n",
        "\n",
        "    if method == 'knapsack':\n",
        "        #picks = knapsack_dp(seg_score, nfps, n_segs, limits)\n",
        "        picks = knapsack_ortools(seg_score, nfps, n_segs, limits)\n",
        "    elif method == 'rank':\n",
        "        order = np.argsort(seg_score)[::-1].tolist()\n",
        "        picks = []\n",
        "        total_len = 0\n",
        "        for i in order:\n",
        "            if total_len + nfps[i] < limits:\n",
        "                picks.append(i)\n",
        "                total_len += nfps[i]\n",
        "    else:\n",
        "        raise KeyError(\"Unknown method {}\".format(method))\n",
        "\n",
        "    summary = np.zeros((1), dtype=np.float32) # this element should be deleted\n",
        "    for seg_idx in range(n_segs):\n",
        "        nf = nfps[seg_idx]\n",
        "        if seg_idx in picks:\n",
        "            tmp = np.ones((nf), dtype=np.float32)\n",
        "        else:\n",
        "            tmp = np.zeros((nf), dtype=np.float32)\n",
        "        summary = np.concatenate((summary, tmp))\n",
        "\n",
        "    summary = np.delete(summary, 0) # delete the first element\n",
        "    return summary\n",
        "\n",
        "\n",
        "def evaluate_summary(machine_summary, user_summary, eval_metric='avg'):\n",
        "    \"\"\"Compare machine summary with user summary (keyshot-based).\n",
        "    Args:\n",
        "    --------------------------------\n",
        "    machine_summary and user_summary should be binary vectors of ndarray type.\n",
        "    eval_metric = {'avg', 'max'}\n",
        "    'avg' averages results of comparing multiple human summaries.\n",
        "    'max' takes the maximum (best) out of multiple comparisons.\n",
        "    \"\"\"\n",
        "    machine_summary = machine_summary.astype(np.float32)\n",
        "    user_summary = user_summary.astype(np.float32)\n",
        "    n_users,n_frames = user_summary.shape\n",
        "\n",
        "    # binarization\n",
        "    machine_summary[machine_summary > 0] = 1\n",
        "    user_summary[user_summary > 0] = 1\n",
        "\n",
        "    if len(machine_summary) > n_frames:\n",
        "        machine_summary = machine_summary[:n_frames]\n",
        "    elif len(machine_summary) < n_frames:\n",
        "        zero_padding = np.zeros((n_frames - len(machine_summary)))\n",
        "        machine_summary = np.concatenate([machine_summary, zero_padding])\n",
        "\n",
        "    f_scores = []\n",
        "    prec_arr = []\n",
        "    rec_arr = []\n",
        "\n",
        "    for user_idx in range(n_users):\n",
        "        gt_summary = user_summary[user_idx,:]\n",
        "        overlap_duration = (machine_summary * gt_summary).sum()\n",
        "        precision = overlap_duration / (machine_summary.sum() + 1e-8)\n",
        "        recall = overlap_duration / (gt_summary.sum() + 1e-8)\n",
        "        if precision == 0 and recall == 0:\n",
        "            f_score = 0.\n",
        "        else:\n",
        "            f_score = (2 * precision * recall) / (precision + recall)\n",
        "        f_scores.append(f_score)\n",
        "        prec_arr.append(precision)\n",
        "        rec_arr.append(recall)\n",
        "\n",
        "    if eval_metric == 'avg':\n",
        "        final_f_score = np.mean(f_scores)\n",
        "        final_prec = np.mean(prec_arr)\n",
        "        final_rec = np.mean(rec_arr)\n",
        "    elif eval_metric == 'max':\n",
        "        final_f_score = np.max(f_scores)\n",
        "        max_idx = np.argmax(f_scores)\n",
        "        final_prec = prec_arr[max_idx]\n",
        "        final_rec = rec_arr[max_idx]\n",
        "    \n",
        "    return final_f_score, final_prec, final_rec\n",
        "\n",
        "\n",
        "def evaluate_user_summaries(user_summary, eval_metric='avg'):\n",
        "    \"\"\"Compare machine summary with user summary (keyshot-based).\n",
        "    Args:\n",
        "    --------------------------------\n",
        "    machine_summary and user_summary should be binary vectors of ndarray type.\n",
        "    eval_metric = {'avg', 'max'}\n",
        "    'avg' averages results of comparing multiple human summaries.\n",
        "    'max' takes the maximum (best) out of multiple comparisons.\n",
        "    \"\"\"\n",
        "    user_summary = user_summary.astype(np.float32)\n",
        "    n_users, n_frames = user_summary.shape\n",
        "\n",
        "    # binarization\n",
        "    user_summary[user_summary > 0] = 1\n",
        "\n",
        "    f_scores = []\n",
        "    prec_arr = []\n",
        "    rec_arr = []\n",
        "\n",
        "    for user_idx in range(n_users):\n",
        "        gt_summary = user_summary[user_idx, :]\n",
        "        for other_user_idx in range(user_idx+1, n_users):\n",
        "            other_gt_summary = user_summary[other_user_idx, :]\n",
        "            overlap_duration = (other_gt_summary * gt_summary).sum()\n",
        "            precision = overlap_duration / (other_gt_summary.sum() + 1e-8)\n",
        "            recall = overlap_duration / (gt_summary.sum() + 1e-8)\n",
        "            if precision == 0 and recall == 0:\n",
        "                f_score = 0.\n",
        "            else:\n",
        "                f_score = (2 * precision * recall) / (precision + recall)\n",
        "            f_scores.append(f_score)\n",
        "            prec_arr.append(precision)\n",
        "            rec_arr.append(recall)\n",
        "\n",
        "\n",
        "    if eval_metric == 'avg':\n",
        "        final_f_score = np.mean(f_scores)\n",
        "        final_prec = np.mean(prec_arr)\n",
        "        final_rec = np.mean(rec_arr)\n",
        "    elif eval_metric == 'max':\n",
        "        final_f_score = np.max(f_scores)\n",
        "        max_idx = np.argmax(f_scores)\n",
        "        final_prec = prec_arr[max_idx]\n",
        "        final_rec = rec_arr[max_idx]\n",
        "\n",
        "    return final_f_score, final_prec, final_rec\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "[0. 0. 1. 1. 0. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9idPvbVfyXSm"
      },
      "source": [
        "###Config.py\n",
        "\n",
        "Verbatim pasted\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9mU69nWyVTp"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "class HParameters:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.verbose = False\n",
        "        self.use_cuda = True\n",
        "        self.cuda_device = 0\n",
        "        self.max_summary_length = 0.15\n",
        "\n",
        "        self.l2_req = 0.00001\n",
        "        self.lr_epochs = [0]\n",
        "        self.lr = [0.00005]\n",
        "\n",
        "        self.epochs_max = 300\n",
        "        self.train_batch_size = 1\n",
        "\n",
        "        self.output_dir = 'ex-10'\n",
        "\n",
        "        self.root = ''\n",
        "        self.datasets=['datasets/eccv16_dataset_summe_google_pool5.h5',\n",
        "                       'datasets/eccv16_dataset_tvsum_google_pool5.h5',\n",
        "                       'datasets/eccv16_dataset_ovp_google_pool5.h5',\n",
        "                       'datasets/eccv16_dataset_youtube_google_pool5.h5']\n",
        "\n",
        "        self.splits = ['splits/tvsum_splits.json',\n",
        "                        'splits/summe_splits.json']\n",
        "\n",
        "        self.splits += ['splits/tvsum_aug_splits.json',\n",
        "                        'splits/summe_aug_splits.json']\n",
        "\n",
        "        return\n",
        "\n",
        "\n",
        "    def get_dataset_by_name(self, dataset_name):\n",
        "        for d in self.datasets:\n",
        "            if dataset_name in d:\n",
        "                return [d]\n",
        "        return None\n",
        "\n",
        "    def load_from_args(self, args):\n",
        "        for key in args:\n",
        "            val = args[key]\n",
        "            if val is not None:\n",
        "                if hasattr(self, key) and isinstance(getattr(self, key), list):\n",
        "                    val = val.split()\n",
        "\n",
        "                setattr(self, key, val)\n",
        "\n",
        "    def __str__(self):\n",
        "        vars = [attr for attr in dir(self) if not callable(getattr(self,attr)) and not (attr.startswith(\"__\") or attr.startswith(\"_\"))]\n",
        "\n",
        "        info_str = ''\n",
        "        for i, var in enumerate(vars):\n",
        "            val = getattr(self, var)\n",
        "            if isinstance(val, Variable):\n",
        "                val = val.data.cpu().numpy().tolist()[0]\n",
        "            info_str += '['+str(i)+'] '+var+': '+str(val)+'\\n'\n",
        "\n",
        "        return info_str\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Tests\n",
        "    hps = HParameters()\n",
        "    print(hps)\n",
        "\n",
        "    args = {'root': 'root_dir',\n",
        "            'datasets': 'set1,set2,set3',\n",
        "            'splits': 'split1, split2',\n",
        "            'new_param_float': 1.23456\n",
        "            }\n",
        "\n",
        "    hps.load_from_args(args)\n",
        "    print(hps)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nn2OIe8lij1k"
      },
      "source": [
        "##Vasnet_model.py\n",
        " along with layer_norm.py\n",
        "\n",
        " editited to fit the new features size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQYDljAjinVi"
      },
      "source": [
        "__author__ = 'Jiri Fajtl'\n",
        "__email__ = 'ok1zjf@gmail.com'\n",
        "__version__= '3.6'\n",
        "__status__ = \"Research\"\n",
        "__date__ = \"1/12/2018\"\n",
        "__license__= \"MIT License\"\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, features, eps=1e-6):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.gamma = nn.Parameter(torch.ones(features))\n",
        "        self.beta = nn.Parameter(torch.zeros(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, apperture=-1, ignore_itself=False, input_size=1024, output_size=1024):\n",
        "        super(SelfAttention, self).__init__()\n",
        "\n",
        "        self.apperture = apperture\n",
        "        self.ignore_itself = ignore_itself\n",
        "\n",
        "        self.m = input_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.K = nn.Linear(in_features=self.m, out_features=self.output_size, bias=False)\n",
        "        self.Q = nn.Linear(in_features=self.m, out_features=self.output_size, bias=False)\n",
        "        self.V = nn.Linear(in_features=self.m, out_features=self.output_size, bias=False)\n",
        "        self.output_linear = nn.Linear(in_features=self.output_size, out_features=self.m, bias=False)\n",
        "\n",
        "        self.drop50 = nn.Dropout(0.5)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        n = x.shape[0]  # sequence length\n",
        "\n",
        "        K = self.K(x)  # ENC (n x m) => (n x H) H= hidden size\n",
        "        Q = self.Q(x)  # ENC (n x m) => (n x H) H= hidden size\n",
        "        V = self.V(x)\n",
        "\n",
        "        Q *= 0.06\n",
        "        logits = torch.matmul(Q, K.transpose(1,0))\n",
        "\n",
        "        if self.ignore_itself:\n",
        "            # Zero the diagonal activations (a distance of each frame with itself)\n",
        "            logits[torch.eye(n).byte()] = -float(\"Inf\")\n",
        "\n",
        "        if self.apperture > 0:\n",
        "            # Set attention to zero to frames further than +/- apperture from the current one\n",
        "            onesmask = torch.ones(n, n)\n",
        "            trimask = torch.tril(onesmask, -self.apperture) + torch.triu(onesmask, self.apperture)\n",
        "            logits[trimask == 1] = -float(\"Inf\")\n",
        "\n",
        "        att_weights_ = nn.functional.softmax(logits, dim=-1)\n",
        "        weights = self.drop50(att_weights_)\n",
        "        y = torch.matmul(V.transpose(1,0), weights).transpose(1,0)\n",
        "        y = self.output_linear(y)\n",
        "\n",
        "        return y, att_weights_\n",
        "\n",
        "\n",
        "\n",
        "class VASNet(nn.Module):\n",
        "\n",
        "    def __init__(self, m = 2048):\n",
        "        super(VASNet, self).__init__()\n",
        "\n",
        "        # self.m = 1024 # cnn features size\n",
        "        self.m = m ## AN EDIT 2021.05.27 change features size to inceptionv3 2048\n",
        "        # self.hidden_size = 1024  ## AN EDIT 2021.05.27 I don't know wtf does this do \n",
        "\n",
        "        self.att = SelfAttention(input_size=self.m, output_size=self.m)\n",
        "        \n",
        "        self.ka = nn.Linear(in_features=self.m, out_features=1024)\n",
        "        self.kb = nn.Linear(in_features=self.ka.out_features, out_features=1024)\n",
        "        self.kc = nn.Linear(in_features=self.kb.out_features, out_features=1024)\n",
        "        self.kd = nn.Linear(in_features=self.ka.out_features, out_features=1)\n",
        "\n",
        "        self.sig = nn.Sigmoid()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.drop50 = nn.Dropout(0.5)\n",
        "        self.softmax = nn.Softmax(dim=0)\n",
        "        self.layer_norm_y = LayerNorm(self.m)\n",
        "        self.layer_norm_ka = LayerNorm(self.ka.out_features)\n",
        "\n",
        "\n",
        "    def forward(self, x, seq_len):\n",
        "\n",
        "        m = x.shape[2] # Feature size\n",
        "\n",
        "        # Place the video frames to the batch dimension to allow for batch arithm. operations.\n",
        "        # Assumes input batch size = 1.\n",
        "        x = x.view(-1, m)\n",
        "        y, att_weights_ = self.att(x)\n",
        "\n",
        "        y = y + x\n",
        "        y = self.drop50(y)\n",
        "        y = self.layer_norm_y(y)\n",
        "\n",
        "        # Frame level importance score regression\n",
        "        # Two layer NN\n",
        "        y = self.ka(y)\n",
        "        y = self.relu(y)\n",
        "        y = self.drop50(y)\n",
        "        y = self.layer_norm_ka(y)\n",
        "\n",
        "        y = self.kd(y)\n",
        "        y = self.sig(y)\n",
        "        y = y.view(1, -1)\n",
        "\n",
        "        return y, att_weights_\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KblPUxg9yMFU"
      },
      "source": [
        "##Main.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ki4-S28yhSC"
      },
      "source": [
        "##AONet class\n",
        "\n",
        "Minor edited to debug"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA3atG8YyCu-"
      },
      "source": [
        "class AONet:\n",
        "\n",
        "    def __init__(self, hps: HParameters):\n",
        "        self.hps = hps\n",
        "        self.model = None\n",
        "        self.log_file = None\n",
        "        self.verbose = hps.verbose\n",
        "\n",
        "\n",
        "    def fix_keys(self, keys, dataset_name = None):\n",
        "        \"\"\"\n",
        "        :param keys:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        # dataset_name = None\n",
        "        if len(self.datasets) == 1:\n",
        "            dataset_name = next(iter(self.datasets))\n",
        "\n",
        "        keys_out = []\n",
        "        for key in keys:\n",
        "            t = key.split('/')\n",
        "            if len(t) != 2:\n",
        "                assert dataset_name is not None, \"ERROR dataset name in some keys is missing but there are multiple dataset {} to choose from\".format(len(self.datasets))\n",
        "\n",
        "                key_name = dataset_name+'/'+key\n",
        "                keys_out.append(key_name)\n",
        "            else:\n",
        "                keys_out.append(key)\n",
        "\n",
        "        return keys_out\n",
        "\n",
        "\n",
        "    def load_datasets(self, datasets = None):\n",
        "        \"\"\"\n",
        "        Loads all h5 datasets from the datasets list into a dictionary self.dataset\n",
        "        referenced by their base filename\n",
        "        :param datasets:  List of dataset filenames\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        if datasets is None:\n",
        "            datasets = self.hps.datasets\n",
        "\n",
        "        datasets_dict = {}\n",
        "        for dataset in datasets:\n",
        "            _, base_filename = os.path.split(dataset)\n",
        "            base_filename, _ = os.path.splitext(base_filename)\n",
        "            print(\"Loading:\", dataset)\n",
        "            # dataset_name = base_filename.split('_')[2]\n",
        "            # print(\"\\tDataset name:\", dataset_name)\n",
        "            datasets_dict[base_filename] = h5py.File(dataset, 'r')\n",
        "\n",
        "        self.datasets = datasets_dict\n",
        "        return datasets_dict\n",
        "\n",
        "\n",
        "    def load_split_file(self, splits_file):\n",
        "\n",
        "        self.dataset_name, self.dataset_type, self.splits = parse_splits_filename(splits_file)\n",
        "        n_folds = len(self.splits)\n",
        "        self.split_file = splits_file\n",
        "        print(\"Loading splits from: \",splits_file)\n",
        "\n",
        "        return n_folds\n",
        "\n",
        "\n",
        "    def select_split(self, split_id):\n",
        "        print(\"Selecting split: \",split_id)\n",
        "\n",
        "        self.split_id = split_id\n",
        "        n_folds = len(self.splits)\n",
        "        assert self.split_id < n_folds, \"split_id (got {}) exceeds {}\".format(self.split_id, n_folds)\n",
        "\n",
        "        split = self.splits[self.split_id]\n",
        "        self.train_keys = split['train_keys']\n",
        "        self.test_keys = split['test_keys']\n",
        "\n",
        "        dataset_filename = self.hps.get_dataset_by_name(self.dataset_name)[0]\n",
        "        _,dataset_filename = os.path.split(dataset_filename)\n",
        "        dataset_filename,_ = os.path.splitext(dataset_filename)\n",
        "        self.train_keys = self.fix_keys(self.train_keys, dataset_filename)\n",
        "        self.test_keys = self.fix_keys(self.test_keys, dataset_filename)\n",
        "        return\n",
        "\n",
        "\n",
        "\n",
        "    def load_model(self, model_filename):\n",
        "        self.model.load_state_dict(torch.load(model_filename, map_location=lambda storage, loc: storage))\n",
        "        return\n",
        "\n",
        "\n",
        "    def initialize(self, cuda_device=None, f_len = 2048):\n",
        "        rnd_seed = 12345\n",
        "        random.seed(rnd_seed)\n",
        "        np.random.seed(rnd_seed)\n",
        "        torch.manual_seed(rnd_seed)\n",
        "\n",
        "        self.model = VASNet(m = f_len)\n",
        "        self.model.eval()\n",
        "        self.model.apply(weights_init)\n",
        "        #print(self.model)\n",
        "\n",
        "        cuda_device = cuda_device or self.hps.cuda_device\n",
        "\n",
        "        if self.hps.use_cuda:\n",
        "            print(\"Setting CUDA device: \",cuda_device)\n",
        "            torch.cuda.set_device(cuda_device)\n",
        "            torch.cuda.manual_seed(rnd_seed)\n",
        "\n",
        "        if self.hps.use_cuda:\n",
        "            self.model.cuda()\n",
        "\n",
        "        return\n",
        "\n",
        "\n",
        "    def get_data(self, key):\n",
        "        key_parts = key.split('/')\n",
        "        assert len(key_parts) == 2, \"ERROR. Wrong key name: \"+key\n",
        "        dataset, key = key_parts\n",
        "        return self.datasets[dataset][key]\n",
        "\n",
        "    def lookup_weights_file(self, data_path):\n",
        "        dataset_type_str = '' if self.dataset_type == '' else self.dataset_type + '_'\n",
        "        weights_filename = data_path + '/models/{}_{}splits_{}_*.tar.pth'.format(self.dataset_name, dataset_type_str, self.split_id)\n",
        "        weights_filename = glob.glob(weights_filename)\n",
        "        if len(weights_filename) == 0:\n",
        "            print(\"Couldn't find model weights: \", weights_filename)\n",
        "            return ''\n",
        "\n",
        "        # Get the first weights filename in the dir\n",
        "        weights_filename = weights_filename[0]\n",
        "        splits_file = data_path + '/splits/{}_{}splits.json'.format(self.dataset_name, dataset_type_str)\n",
        "\n",
        "        return weights_filename, splits_file\n",
        "\n",
        "\n",
        "    def train(self, output_dir='EX-0'):\n",
        "\n",
        "        print(\"Initializing VASNet model and optimizer...\")\n",
        "        self.model.train()\n",
        "\n",
        "        criterion = nn.MSELoss()\n",
        "\n",
        "        if self.hps.use_cuda:\n",
        "            criterion = criterion.cuda()\n",
        "\n",
        "        parameters = filter(lambda p: p.requires_grad, self.model.parameters())\n",
        "        self.optimizer = torch.optim.Adam(parameters, lr=self.hps.lr[0], weight_decay=self.hps.l2_req)\n",
        "\n",
        "        print(\"Starting training...\")\n",
        "\n",
        "        max_val_fscore = 0\n",
        "        max_val_fscore_epoch = 0\n",
        "        train_keys = self.train_keys[:]\n",
        "\n",
        "        lr = self.hps.lr[0]\n",
        "        for epoch in range(self.hps.epochs_max):\n",
        "\n",
        "            if epoch % 50 == 0 : print(\"Epoch: {0:6}\".format(str(epoch)+\"/\"+str(self.hps.epochs_max)), end='') #AN EDIT: only report for every 50 epoch\n",
        "            self.model.train()\n",
        "            avg_loss = []\n",
        "\n",
        "            random.shuffle(train_keys)\n",
        "\n",
        "            for i, key in enumerate(train_keys):\n",
        "                dataset = self.get_data(key)\n",
        "                seq = dataset['features'][...]\n",
        "                \n",
        "                seq = torch.from_numpy(seq).unsqueeze(0)\n",
        "\n",
        "                target = dataset['gtscore'][...]\n",
        "                target = torch.from_numpy(target).unsqueeze(0)\n",
        "\n",
        "                # Normalize frame scores\n",
        "                target -= target.min()\n",
        "                target /= target.max()\n",
        "\n",
        "                if self.hps.use_cuda:\n",
        "                    seq, target = seq.float().cuda(), target.float().cuda()\n",
        "\n",
        "                # print(seq.shape)\n",
        "                seq_len = seq.shape[1]\n",
        "                y, _ = self.model(seq,seq_len)\n",
        "                loss_att = 0\n",
        "                # print(i, key, target)\n",
        "\n",
        "                # print(y.shape, target.shape)\n",
        "                loss = criterion(y, target)\n",
        "\n",
        "                # print(loss)\n",
        "                # loss2 = y.sum()/seq_len\n",
        "                loss = loss + loss_att\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                avg_loss.append([float(loss), float(loss_att)])\n",
        "\n",
        "           \n",
        "            # Evaluate test dataset\n",
        "            val_fscore, video_scores = self.eval(self.test_keys)\n",
        "            if max_val_fscore < val_fscore:\n",
        "                max_val_fscore = val_fscore\n",
        "                max_val_fscore_epoch = epoch\n",
        "\n",
        "            avg_loss = np.array(avg_loss)\n",
        "            if epoch % 50 == 0 :  print(\"   Train loss: {0:.05f}\".format(np.mean(avg_loss[:, 0])), end='')  #AN EDIT: only report for every 50 epoch\n",
        "            if epoch % 50 == 0 :  print('   Test F-score avg/max: {0:0.5}/{1:0.5}'.format(val_fscore, max_val_fscore))  #AN EDIT: only report for every 50 epoch\n",
        "\n",
        "            if self.verbose:\n",
        "                video_scores = [[\"No\", \"Video\", \"F-score\"]] + video_scores\n",
        "                print_table(video_scores, cell_width=[3,40,8])\n",
        "\n",
        "            # Save model weights\n",
        "            path, filename = os.path.split(self.split_file)\n",
        "            base_filename, _ = os.path.splitext(filename)\n",
        "            path = os.path.join(output_dir, 'models_temp', base_filename+'_'+str(self.split_id))\n",
        "            os.makedirs(path, exist_ok=True)\n",
        "            filename = str(epoch)+'_'+str(round(val_fscore*100,3))+'.pth.tar'\n",
        "            torch.save(self.model.state_dict(), os.path.join(path, filename))\n",
        "\n",
        "        return max_val_fscore, max_val_fscore_epoch\n",
        "\n",
        "\n",
        "    def eval(self, keys, results_filename=None):\n",
        "\n",
        "        self.model.eval()\n",
        "        summary = {}\n",
        "        att_vecs = {}\n",
        "        with torch.no_grad():\n",
        "            for i, key in enumerate(keys):\n",
        "                data = self.get_data(key)\n",
        "                # seq = self.dataset[key]['features'][...]\n",
        "                seq = data['features'][...]\n",
        "                seq = torch.from_numpy(seq).unsqueeze(0)\n",
        "\n",
        "                if self.hps.use_cuda:\n",
        "                    seq = seq.float().cuda()\n",
        "\n",
        "                y, att_vec = self.model(seq, seq.shape[1])\n",
        "                summary[key] = y[0].detach().cpu().numpy()\n",
        "                att_vecs[key] = att_vec.detach().cpu().numpy()\n",
        "\n",
        "        f_score, video_scores = self.eval_summary(summary, keys, metric=self.dataset_name,\n",
        "                    results_filename=results_filename, att_vecs=att_vecs)\n",
        "\n",
        "        return f_score, video_scores\n",
        "\n",
        "\n",
        "    def eval_summary(self, machine_summary_activations, test_keys, results_filename=None, metric='tvsum', att_vecs=None):\n",
        "\n",
        "        eval_metric = 'avg' if metric == 'tvsum' else 'max'\n",
        "\n",
        "        if results_filename is not None:\n",
        "            h5_res = h5py.File(results_filename, 'w')\n",
        "\n",
        "        fms = []\n",
        "        video_scores = []\n",
        "        for key_idx, key in enumerate(test_keys):\n",
        "            d = self.get_data(key)\n",
        "            probs = machine_summary_activations[key]\n",
        "\n",
        "            if 'change_points' not in d:\n",
        "                print(\"ERROR: No change points in dataset/video \",key)\n",
        "\n",
        "            cps = d['change_points'][...]\n",
        "            num_frames = d['n_frames'][()]\n",
        "            nfps = d['n_frame_per_seg'][...].tolist()\n",
        "            positions = d['picks'][...]\n",
        "            user_summary = d['user_summary'][...]\n",
        "\n",
        "            machine_summary = generate_summary(probs, cps, num_frames, nfps, positions)\n",
        "            fm, _, _ = evaluate_summary(machine_summary, user_summary, eval_metric)\n",
        "            fms.append(fm)\n",
        "\n",
        "            # Reporting & logging\n",
        "            video_scores.append([key_idx + 1, key, \"{:.1%}\".format(fm)])\n",
        "\n",
        "            if results_filename:\n",
        "                gt = d['gtscore'][...]\n",
        "                h5_res.create_dataset(key + '/score', data=probs)\n",
        "                h5_res.create_dataset(key + '/machine_summary', data=machine_summary)\n",
        "                h5_res.create_dataset(key + '/gtscore', data=gt)\n",
        "                h5_res.create_dataset(key + '/fm', data=fm)\n",
        "                h5_res.create_dataset(key + '/picks', data=positions)\n",
        "\n",
        "                video_name = key.split('/')[1]\n",
        "                if 'video_name' in d:\n",
        "                    video_name = d['video_name'][...]\n",
        "                h5_res.create_dataset(key + '/video_name', data=video_name)\n",
        "\n",
        "                if att_vecs is not None:\n",
        "                    h5_res.create_dataset(key + '/att', data=att_vecs[key])\n",
        "\n",
        "        mean_fm = np.mean(fms)\n",
        "\n",
        "        # Reporting & logging\n",
        "        if results_filename is not None:\n",
        "            h5_res.close()\n",
        "\n",
        "        return mean_fm, video_scores\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ7M_9kWXwGz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HurpszkpXzoy"
      },
      "source": [
        "### Auxilary function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seNlORB6X2Xb"
      },
      "source": [
        "def parse_splits_filename(splits_filename):\n",
        "    # Parse split file and count number of k_folds\n",
        "    spath, sfname = os.path.split(splits_filename)\n",
        "    sfname, _ = os.path.splitext(sfname)\n",
        "    dataset_name = sfname.split('_')[0]  # Get dataset name e.g. tvsum\n",
        "    dataset_type = sfname.split('_')[1]  # augmentation type e.g. aug\n",
        "\n",
        "    # The keyword 'splits' is used as the filename fields terminator from historical reasons.\n",
        "    if dataset_type == 'splits':\n",
        "        # Split type is not present\n",
        "        dataset_type = ''\n",
        "\n",
        "    # Get number of discrete splits within each split json file\n",
        "    with open(splits_filename, 'r') as sf:\n",
        "        splits = json.load(sf)\n",
        "\n",
        "    return dataset_name, dataset_type, splits\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname == 'Linear':\n",
        "        init.xavier_uniform_(m.weight, gain=np.sqrt(2.0))\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "886kf7foyk1I"
      },
      "source": [
        "##Train function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCzvZEl1zEtn"
      },
      "source": [
        "### Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm3vhc5ixLDE"
      },
      "source": [
        "def train(hps, f_len = 2048):\n",
        "    os.makedirs(hps.output_dir, exist_ok=True)\n",
        "    os.makedirs(os.path.join(hps.output_dir, 'splits'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(hps.output_dir, 'code'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(hps.output_dir, 'models'), exist_ok=True)\n",
        "    os.system('cp -f splits/*.json  ' + hps.output_dir + '/splits/')\n",
        "    os.system('cp *.py ' + hps.output_dir + '/code/')\n",
        "\n",
        "    # Create a file to collect results from all splits\n",
        "    f = open(hps.output_dir + '/results.txt', 'wt')\n",
        "\n",
        "    for split_filename in hps.splits:\n",
        "        dataset_name, dataset_type, splits = parse_splits_filename(split_filename)\n",
        "\n",
        "        # For no augmentation use only a dataset corresponding to the split file\n",
        "        datasets = None\n",
        "        if dataset_type == '':\n",
        "            datasets = hps.get_dataset_by_name(dataset_name)\n",
        "\n",
        "        if datasets is None:\n",
        "            datasets = hps.datasets\n",
        "\n",
        "        f_avg = 0\n",
        "        n_folds = len(splits)\n",
        "        for split_id in range(n_folds):\n",
        "            ao = AONet(hps)\n",
        "            ao.load_datasets(datasets=datasets)\n",
        "\n",
        "            ao.initialize(f_len = f_len) # AN EDIT : pass f_len through\n",
        "            \n",
        "            ao.load_split_file(splits_file=split_filename)\n",
        "            ao.select_split(split_id=split_id)\n",
        "\n",
        "            fscore, fscore_epoch = ao.train(output_dir=hps.output_dir)\n",
        "            f_avg += fscore\n",
        "\n",
        "            # Log F-score for this split_id\n",
        "            f.write(split_filename + ', ' + str(split_id) + ', ' + str(fscore) + ', ' + str(fscore_epoch) + '\\n')\n",
        "            f.flush()\n",
        "\n",
        "            # Save model with the highest F score\n",
        "            _, log_file = os.path.split(split_filename)\n",
        "            log_dir, _ = os.path.splitext(log_file)\n",
        "            log_dir += '_' + str(split_id)\n",
        "            log_file = os.path.join(hps.output_dir, 'models', log_dir) + '_' + str(fscore) + '.tar.pth'\n",
        "\n",
        "            os.makedirs(os.path.join(hps.output_dir, 'models', ), exist_ok=True)\n",
        "            os.system('mv ' + hps.output_dir + '/models_temp/' + log_dir + '/' + str(fscore_epoch) + '_*.pth.tar ' + log_file)\n",
        "            os.system('rm -rf ' + hps.output_dir + '/models_temp/' + log_dir)\n",
        "\n",
        "            print(\"Split: {0:}   Best F-score: {1:0.5f}   Model: {2:}\".format(split_filename, fscore, log_file))\n",
        "\n",
        "        # Write average F-score for all splits to the results.txt file\n",
        "        f_avg /= n_folds\n",
        "        f.write(split_filename + ', ' + str('avg') + ', ' + str(f_avg) + '\\n')\n",
        "        f.flush()\n",
        "\n",
        "    f.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOfBuNTPyy9m"
      },
      "source": [
        "### Calling train function\n",
        "\n",
        "Edit path to h5 and split file before training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_S6upHNc8sL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac52a2f2-f871-43ec-f811-427664836c0e"
      },
      "source": [
        "import sys\n",
        "\n",
        "import os\n",
        "\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser(\"PyTorch implementation of paper \\\"Summarizing Videos with Attention\\\"\")\n",
        "parser.add_argument('-r', '--root', type=str, default='', help=\"Project root directory\")\n",
        "parser.add_argument('-d', '--datasets', type=str, help=\"Path to a comma separated list of h5 datasets\")\n",
        "parser.add_argument('-s', '--splits', type=str, help=\"Comma separated list of split files.\")\n",
        "parser.add_argument('-t', '--train', action='store_true', help=\"Train\")\n",
        "parser.add_argument('-v', '--verbose', action='store_true', help=\"Prints out more messages\")\n",
        "parser.add_argument('-o', '--output-dir', type=str, default='data', help=\"Experiment name\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['-o', '--output-dir'], dest='output_dir', nargs=None, const=None, default='data', type=<class 'str'>, choices=None, help='Experiment name', metavar=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9tqjHH12Q4u",
        "outputId": "c2e296f3-f014-4830-b633-9e8822dddbb1"
      },
      "source": [
        "szRootDir = '/content/drive/MyDrive/0.Desktop/VSUM-Colab' #Duy\n",
        "szVASNetRootDir = szRootDir + '/VASNet' \n",
        "szUITTVSUMRootDir = szRootDir + '/UIT-VSUM' \n",
        "%cd $szVASNetRootDir \n",
        "!pwd\n",
        "\n",
        "h5_orig_file = szVASNetRootDir + '/datasets/eccv16_dataset_tvsum_google_pool5.h5' \n",
        "h5_new_data_file = szUITTVSUMRootDir + '/eccv16_dataset_tvsum_google_pool5-xreplace-by-inceptionv3_avg.h5  '\n",
        "output_dir = szUITTVSUMRootDir + '/vasnet_inceptionv3_avg/ '\n",
        "split_dir = szVASNetRootDir + '/splits/tvsum_splits.json'\n",
        "\n",
        "output_dir_orig = szUITTVSUMRootDir + '/vasnet_googlenet/ '"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1UnHkRTf9TYt790JF-rSwz0LnpK9HeZ6E/Colab/VASNet\n",
            "/content/drive/.shortcut-targets-by-id/1UnHkRTf9TYt790JF-rSwz0LnpK9HeZ6E/Colab/VASNet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYUKrEF8LDf_"
      },
      "source": [
        "# googlenet\n",
        "import timeit\n",
        "import datetime \n",
        "import sys\n",
        "import h5py\n",
        "import json\n",
        "import random\n",
        "\n",
        "def train_wrapper(model):\n",
        "  sys.argv = \"main.py \"\n",
        "  sys.argv += '-d ' + h5_orig_file\n",
        "  sys.argv += '  -o ' + output_dir_orig\n",
        "  sys.argv += '  -s ' + split_dir\n",
        "  sys.argv = sys.argv.split()\n",
        "\n",
        "  args = parser.parse_args()\n",
        "\n",
        "  #Get feature length\n",
        "  #h5 = h5py.File(colab_path + 'eccv16_dataset_tvsum_google_pool5-replace-by-' + model + '.h5', 'r');\n",
        "  #f_len =(h5['video_1']['features'].shape[1])\n",
        "  f_len = 1024\n",
        "\n",
        "  # MAIN\n",
        "  #======================\n",
        "  hps = HParameters()\n",
        "  hps.load_from_args(args.__dict__)\n",
        "\n",
        "  train(hps, f_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjYdkyvE4OOD",
        "outputId": "ba1ec91d-1808-4797-bf82-855b11721bc9"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from config import  *\n",
        "from layer_norm import  *\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import time\n",
        "import glob\n",
        "import random\n",
        "import argparse\n",
        "import h5py\n",
        "import json\n",
        "import torch.nn.init as init\n",
        "\n",
        "train_wrapper('vgg16')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading: /content/drive/MyDrive/0.Desktop/VSUM-Colab/VASNet/datasets/eccv16_dataset_tvsum_google_pool5.h5\n",
            "Setting CUDA device:  0\n",
            "Loading splits from:  /content/drive/MyDrive/0.Desktop/VSUM-Colab/VASNet/splits/tvsum_splits.json\n",
            "Selecting split:  0\n",
            "Initializing VASNet model and optimizer...\n",
            "Starting training...\n",
            "Epoch: 0/300    Train loss: 0.12937   Test F-score avg/max: 0.50908/0.50908\n",
            "Epoch: 50/300   Train loss: 0.03394   Test F-score avg/max: 0.59682/0.59682\n",
            "Epoch: 100/300   Train loss: 0.02727   Test F-score avg/max: 0.59466/0.60108\n",
            "Epoch: 150/300   Train loss: 0.02291   Test F-score avg/max: 0.59975/0.60508\n",
            "Epoch: 200/300   Train loss: 0.02051   Test F-score avg/max: 0.58917/0.60775\n",
            "Epoch: 250/300   Train loss: 0.01877   Test F-score avg/max: 0.57212/0.61289\n",
            "Split: /content/drive/MyDrive/0.Desktop/VSUM-Colab/VASNet/splits/tvsum_splits.json   Best F-score: 0.61289   Model: /content/drive/MyDrive/0.Desktop/VSUM-Colab/UIT-VSUM/vasnet_googlenet/models/tvsum_splits_0_0.612890321913846.tar.pth\n",
            "Loading: /content/drive/MyDrive/0.Desktop/VSUM-Colab/VASNet/datasets/eccv16_dataset_tvsum_google_pool5.h5\n",
            "Setting CUDA device:  0\n",
            "Loading splits from:  /content/drive/MyDrive/0.Desktop/VSUM-Colab/VASNet/splits/tvsum_splits.json\n",
            "Selecting split:  1\n",
            "Initializing VASNet model and optimizer...\n",
            "Starting training...\n",
            "Epoch: 0/300    Train loss: 0.13174   Test F-score avg/max: 0.48899/0.48899\n",
            "Epoch: 50/300   Train loss: 0.03457   Test F-score avg/max: 0.61398/0.63252\n",
            "Epoch: 100/300   Train loss: 0.02712   Test F-score avg/max: 0.5997/0.63252\n",
            "Epoch: 150/300   Train loss: 0.02317   Test F-score avg/max: 0.59595/0.63252\n",
            "Epoch: 200/300   Train loss: 0.02123   Test F-score avg/max: 0.58427/0.63252\n",
            "Epoch: 250/300   Train loss: 0.01824   Test F-score avg/max: 0.58285/0.63252\n",
            "Split: /content/drive/MyDrive/0.Desktop/VSUM-Colab/VASNet/splits/tvsum_splits.json   Best F-score: 0.63252   Model: /content/drive/MyDrive/0.Desktop/VSUM-Colab/UIT-VSUM/vasnet_googlenet/models/tvsum_splits_1_0.6325221281468341.tar.pth\n",
            "Loading: /content/drive/MyDrive/0.Desktop/VSUM-Colab/VASNet/datasets/eccv16_dataset_tvsum_google_pool5.h5\n",
            "Setting CUDA device:  0\n",
            "Loading splits from:  /content/drive/MyDrive/0.Desktop/VSUM-Colab/VASNet/splits/tvsum_splits.json\n",
            "Selecting split:  2\n",
            "Initializing VASNet model and optimizer...\n",
            "Starting training...\n",
            "Epoch: 0/300    Train loss: 0.14151   Test F-score avg/max: 0.44302/0.44302\n",
            "Epoch: 50/300   Train loss: 0.03588   Test F-score avg/max: 0.58065/0.58893\n",
            "Epoch: 100/300   Train loss: 0.02837   Test F-score avg/max: 0.56848/0.58893\n",
            "Epoch: 150/300   Train loss: 0.02341   Test F-score avg/max: 0.55149/0.58893\n",
            "Epoch: 200/300   Train loss: 0.02053   Test F-score avg/max: 0.55195/0.58893\n",
            "Epoch: 250/300   Train loss: 0.01898   Test F-score avg/max: 0.54273/0.58893\n",
            "Split: /content/drive/MyDrive/0.Desktop/VSUM-Colab/VASNet/splits/tvsum_splits.json   Best F-score: 0.58893   Model: /content/drive/MyDrive/0.Desktop/VSUM-Colab/UIT-VSUM/vasnet_googlenet/models/tvsum_splits_2_0.5889252255381411.tar.pth\n",
            "Loading: /content/drive/MyDrive/0.Desktop/VSUM-Colab/VASNet/datasets/eccv16_dataset_tvsum_google_pool5.h5\n",
            "Setting CUDA device:  0\n",
            "Loading splits from:  /content/drive/MyDrive/0.Desktop/VSUM-Colab/VASNet/splits/tvsum_splits.json\n",
            "Selecting split:  3\n",
            "Initializing VASNet model and optimizer...\n",
            "Starting training...\n",
            "Epoch: 0/300    Train loss: 0.13675   Test F-score avg/max: 0.5447/0.5447\n",
            "Epoch: 50/300   Train loss: 0.03360   Test F-score avg/max: 0.62279/0.62909\n",
            "Epoch: 100/300   Train loss: 0.02733   Test F-score avg/max: 0.63038/0.63226\n",
            "Epoch: 150/300   Train loss: 0.02242   Test F-score avg/max: 0.62913/0.6416\n",
            "Epoch: 200/300   Train loss: 0.01985   Test F-score avg/max: 0.63063/0.6416\n",
            "Epoch: 250/300   Train loss: 0.01846   Test F-score avg/max: 0.63039/0.6416\n",
            "Split: /content/drive/MyDrive/0.Desktop/VSUM-Colab/VASNet/splits/tvsum_splits.json   Best F-score: 0.64160   Model: /content/drive/MyDrive/0.Desktop/VSUM-Colab/UIT-VSUM/vasnet_googlenet/models/tvsum_splits_3_0.6416011807163637.tar.pth\n",
            "Loading: /content/drive/MyDrive/0.Desktop/VSUM-Colab/VASNet/datasets/eccv16_dataset_tvsum_google_pool5.h5\n",
            "Setting CUDA device:  0\n",
            "Loading splits from:  /content/drive/MyDrive/0.Desktop/VSUM-Colab/VASNet/splits/tvsum_splits.json\n",
            "Selecting split:  4\n",
            "Initializing VASNet model and optimizer...\n",
            "Starting training...\n",
            "Epoch: 0/300    Train loss: 0.13888   Test F-score avg/max: 0.51822/0.51822\n",
            "Epoch: 50/300   Train loss: 0.03331   Test F-score avg/max: 0.56128/0.58268\n",
            "Epoch: 100/300   Train loss: 0.02683   Test F-score avg/max: 0.56433/0.58268\n",
            "Epoch: 150/300   Train loss: 0.02268   Test F-score avg/max: 0.54353/0.58268\n",
            "Epoch: 200/300   Train loss: 0.01987   Test F-score avg/max: 0.53759/0.58268\n",
            "Epoch: 250/300   Train loss: 0.01826   Test F-score avg/max: 0.55448/0.58268\n",
            "Split: /content/drive/MyDrive/0.Desktop/VSUM-Colab/VASNet/splits/tvsum_splits.json   Best F-score: 0.58268   Model: /content/drive/MyDrive/0.Desktop/VSUM-Colab/UIT-VSUM/vasnet_googlenet/models/tvsum_splits_4_0.5826774846461059.tar.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDiRqGvivq70"
      },
      "source": [
        "# inceptionv3\n",
        "import timeit\n",
        "import datetime \n",
        "import sys\n",
        "import h5py\n",
        "import json\n",
        "import random\n",
        "\n",
        "def train_wrapper(model):\n",
        "  sys.argv = \"main.py \"\n",
        "  sys.argv += '-d ' + h5_new_data_file\n",
        "  sys.argv += '  -o ' + output_dir\n",
        "  sys.argv += '  -s ' + split_dir\n",
        "  sys.argv = sys.argv.split()\n",
        "\n",
        "  args = parser.parse_args()\n",
        "\n",
        "  #Get feature length\n",
        "  #h5 = h5py.File(colab_path + 'eccv16_dataset_tvsum_google_pool5-replace-by-' + model + '.h5', 'r');\n",
        "  #f_len =(h5['video_1']['features'].shape[1])\n",
        "  f_len = 2048\n",
        "\n",
        "  # MAIN\n",
        "  #======================\n",
        "  hps = HParameters()\n",
        "  hps.load_from_args(args.__dict__)\n",
        "\n",
        "  train(hps, f_len)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAg20ltp4xNr"
      },
      "source": [
        "!ls '/content/drive/MyDrive/0.Desktop/VSUM-Colab/UIT-VSUM/'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pM1aVgeyybG"
      },
      "source": [
        "# for i in [  'resnet50', 'inceptionv3' ,'vgg16', 'efficientnet']:\n",
        "for i in ['vgg16' ]:\n",
        "\n",
        "  f = open(colab_path + \"retrain_vasnet_with_\" + i + \".log\", \"a\")\n",
        "  \n",
        "  start = time.perf_counter()\n",
        "  \n",
        "  train_wrapper(i)\n",
        "  end = time.perf_counter() \n",
        "\n",
        "  report_time = \"\\n\" + str(datetime.datetime.now()) + \" \" + str(i) + \" \" + str(end - start) \n",
        "  print(report_time)\n",
        "  f.write( report_time )\n",
        "  f.flush()\n",
        "  f.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ttf0qXR06rG1"
      },
      "source": [
        "## Show results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VVwOb6c-AZu"
      },
      "source": [
        " !awk '{ total += $4; count++ } END { print total/count/60 }'   /content/drive/MyDrive/VSum/Colab/retrain_vasnet_with_efficientnet.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkVstv_4v0Va"
      },
      "source": [
        "colab_path = '/content/drive/MyDrive/VSum/Colab/' # AN\n",
        "\n",
        "for model in [  'resnet50', 'inception_v3' ,'vgg16', 'efficientnet']:\n",
        "\n",
        "  output_folder = colab_path + 'vasnet_'+ model + '_retrain/   '\n",
        "  training_time_log = colab_path + \"retrain_vasnet_with_\" + model + \".log\"\n",
        "\n",
        "  print(\"\\n---------------\", model, \"-----s--------\\n\")\n",
        "  !cat $training_time_log\n",
        "  !awk '{ total += $4; count++ } END { print total/count }'  \"$training_time_log\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP8SKEyT84Kr"
      },
      "source": [
        "colab_path = '/content/drive/MyDrive/VSum/Colab/' # AN\n",
        "\n",
        "for model in [  'resnet50', 'inception_v3' ,'vgg16', 'efficientnet']:\n",
        "\n",
        "  output_folder = colab_path + 'vasnet_'+ model + '_retrain'\n",
        "  training_time_log = colab_path + \"retrain_vasnet_with_\" + model + \".log\"\n",
        "\n",
        "  print(\"\\n---------------\", model, \"-----s--------\\n\")\n",
        "  !cat \"$output_folder\"*/results.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59R-1l8D9QAo"
      },
      "source": [
        "| model | h5filesize | features length  | training time (minute) | avg f1 all split | best split \n",
        "--- | --- | --- | --- | --- | --- \n",
        "google net (original) |119 MiB | 1024 | 18.72 | 61.43% | 64.18% (split 3) \n",
        "resnet 50 | 211 MiB | 2048 | 53.569 | 57.05% | 60.72% (split 3) \n",
        "inception_v3 | 211 MiB | 2048 | 55  |  58.83% | 62.66% (split3) \n",
        "vgg16 | 73 MiB | 512 | 11 | 55.10% | 56.81% (split 3)\n",
        "efficientnet | 257 MiB | 2506 | 79 | 59.88%  | 62.88% (split 3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE1KyTRy8JxD"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWmjaEPW2TRr"
      },
      "source": [
        "```\u001d"
      ]
    }
  ]
}